[["introduzione-alla-guida.html", "Guida pratica alla calibrazione, allo studio dellinvarianza e allo scoring di strumenti psicologici tramite lItem Response Theory (IRT) in R Introduzione alla guida", " Guida pratica alla calibrazione, allo studio dellinvarianza e allo scoring di strumenti psicologici tramite lItem Response Theory (IRT) in R a cura di Francesco Sanson Introduzione alla guida La presente guida è pensata come introduzione alla calibrazione e allo scoring di strumenti psicologici tramite lItem Response Theory (IRT). A questo scopo, verrà utilizzato lambiente di siviluppo R e il pacchetto mirt (Chalmers, 2012). La guida completa allutilizzo del pacchetto può essere scaricata da qui. Sebbene il pacchetto mirt permetta di effettuare la calibrazione sia di strumenti unidimensionali che multidimensionali, questa guida sarà focalizzata sui modelli unidimensionali. Per quanto riguarda gli strumenti undimensionali dicotomici, verranno utilizzati i seguenti modelli: ad un parametro (1PL; Birnbaum, 1968; Hambleton et al., 1991); due parametri (2PL; Birnbaum, 1968); Verrà, inoltre, fatto un accenno al modello 3PL (Birnbaum, 1968). Per quanto riguarda gli strumenti unidimensionali politomici, verrà utilizzato il modello graded (Samejima, 1968). Verrà poi mostrato come condurre il Differential Item Functioning (DIF; Thissen et al., 1988). Infine, verrà mostrato come effettuare lo scoring di uno strumento utilizzando l Expected a Posteriori Score (EAP; Bock e Mislevy, 1982). "],["installare-i-pacchetti.html", "Installare i pacchetti", " Installare i pacchetti Per prima cosa, installiamo il pacchetto mirt tramite il comando install.packages('mirt') o tramite linterfaccia di RStudio. Installiamo poi la libreria tidyverse (Wickham et al., 2019) , la quale ci servirà per alcune operazioni da svolgere durante il tutorial. install.packages('tidyverse') Installiamo, infine, la libreria haven (Wickham &amp; Miller, 2021) per limportazione di dati in formato .sav (in RStudio la libreria è già installata). install.packages('haven') Come sempre in R, prima di iniziare a lavorare, carichiamo le librerie. library(mirt) library(tidyverse) library(haven) Proseguiremo ora prima allanalisi dei modelli unidimensionali dicotomici e poi ai modelli unidimensionali politomici. "],["calibrazione-di-strumenti-unidimensionali-con-item-dicotomici.html", "Calibrazione di strumenti unidimensionali con item dicotomici", " Calibrazione di strumenti unidimensionali con item dicotomici In questa sezione tratteremo gli strumenti unidimensionali con item dicotomici, ovvero quegli strumenti dove tutti gli item misurano lo stesso tratto latente (theta) e tutte le risposte agli item sono dicotomiche (no/sì - falso/vero - 0/1). Esitono diversi modelli per la calibrazione di strumenti unidimensionali dicotomici, i quali si differenziano per il numero di parametri stimati. Di seguito un riassunto sommario. Modello di Rasch Considera che tutti gli item abbiano una capacità discriminativa uguale ad 1. Stima la location (b) per ogni item. Modello 1PL Impone a tutti gli item la stessa capacità discriminativa (a), la quale non viene però fissata ad 1. Stima la location (b) per ogni item. Modello 2PL Stima la capacità discriminativa (a) e la location per ogni item (b). Modello 3PL Rispetto al modello 2PL, aggiunge un ulteriore parametro per ogni item, il guessing (g), ovvero la stima di quanto il caso influisca sulla risposta. Da utilizzare solo con le scale di abilità per le quali vi è la possibilità di indovinare la risposta, non adatto invece a strumenti in cui il caso è irrilevante (ad esempio, risposte aperte poi ricodificate in sbagliato/giusto). Caricare i dati Per la presente guida, utilizzeremo un database di prova, gentilmente messo a disposizione dal Laboratorio di Psicometria dellUniversità di Firenze, contenente 7 item a risposta aperta, poi ricodificata in dicotomica (0,1). Potete scaricare il database da qui e importarlo tramite la finestra di import di RStudio. In alternativa, potete importarlo tramite il codice come nellesempio sottostante: TEST.DIC&lt;- read_sav(&quot;C:/Users/.../TEST.DIC.sav&quot;) NOTA: la directory in esempio è relativa al mio computer e rappresenta dove ho salvato il file TEST.DIC. Per rimportarlo tramite il codice, dovrete cambiare la directory impostando quella relativa al vostro file. Il database contiene due variabili socio-demografiche e i 7 item già ricodificati in sbagliato (0) e giusto. Ai fini delle analisi IRT, ci interessano solo gli item, i quali vanno selezionati come segue: TEST.DIC.item&lt;-TEST.DIC[,3:9] View(TEST.DIC.item) Calibrazione del modello Sebbene non sia il primo passaggio in termini di studio di un modello IRT, per poter procedere con le analisi dobbiamo in primo luogo calibrare il modello. Poiché i 7 del test prevedono luso di risposte aperte, le quali rendono linfluenza del guessing minima, utilizzeremo i modelli 1PL e 2PL, per poi effettuare un confronto fra i due. Calibrazione modello 1PL In primo luogo dobbiamo definire la struttura fattoriale tramite la funzione mirt.model(). Essendo un modello unidimensionale tutti gli item satureranno su di un unico fattore (F1=1-7). Poiché il modello è ad un parametro (1PL), inoltre, imporremo il vincolo di uguaglianza alle saturazioni utilizzando largomento CONSTRAIN = (1-7, a1). Nella definizione della struttura, gli item non vanno richiamati per nome ma per posizione ordinale (ad esempio, 1-7 significa includi tutti gli item dal primo al settimo). #Struttura fattoriale del modello 1PL fct.str.1PL &lt;- mirt.model( &#39;F1 = 1-7 CONSTRAIN = (1-7, a1)&#39; ) Per calibrare il modello, utilizzeremo la funzione mirt(). Largomento itemtype va impostato sul modello 2PL, poiché il modello 1PL è una derivazione del modello 2PL al quale è stato aggiunto un vincolo sulla capacità discriminativa. #Calibrazione modello 1PL MOD.1PL &lt;- mirt(data=TEST.DIC.item, model=fct.str.1PL, itemtype = &quot;2PL&quot;) ## Iteration: 1, Log-Lik: -1606.401, Max-Change: 0.31127 Iteration: 2, Log-Lik: -1577.400, Max-Change: 0.17846 Iteration: 3, Log-Lik: -1569.818, Max-Change: 0.09674 Iteration: 4, Log-Lik: -1567.765, Max-Change: 0.05288 Iteration: 5, Log-Lik: -1567.171, Max-Change: 0.02965 Iteration: 6, Log-Lik: -1566.991, Max-Change: 0.01610 Iteration: 7, Log-Lik: -1566.930, Max-Change: 0.00765 Iteration: 8, Log-Lik: -1566.918, Max-Change: 0.00394 Iteration: 9, Log-Lik: -1566.914, Max-Change: 0.00235 Iteration: 10, Log-Lik: -1566.912, Max-Change: 0.00103 Iteration: 11, Log-Lik: -1566.912, Max-Change: 0.00045 Iteration: 12, Log-Lik: -1566.912, Max-Change: 0.00031 Iteration: 13, Log-Lik: -1566.912, Max-Change: 0.00029 Iteration: 14, Log-Lik: -1566.912, Max-Change: 0.00011 Iteration: 15, Log-Lik: -1566.912, Max-Change: 0.00008 Verifica delle assunzioni Prima di procedere con la stima del modello 2PL, verifichiamo lassunzione di indipendendeza locale, la quale è un prerequisito per il fit di un modello IRT unidimensionale. Per farlo, utilizzeremo la statistica di Local Dependence (LD; Chen &amp; Thissen, 1997) tramite la funzione residuals(). #Assunzoni 1PL residuals(MOD.1PL,type=&#39;LD&#39;,df.p=TRUE) #LD per il modello 1PL ## Degrees of freedom (lower triangle) and p-values: ## ## ITEM_DIC_1 ITEM_DIC_2 ITEM_DIC_3 ITEM_DIC_4 ITEM_DIC_5 ## ITEM_DIC_1 NA 0.446 0.793 0.002 0.909 ## ITEM_DIC_2 1 NA 0.218 0.122 0.813 ## ITEM_DIC_3 1 1.000 NA 0.026 0.110 ## ITEM_DIC_4 1 1.000 1.000 NA 0.009 ## ITEM_DIC_5 1 1.000 1.000 1.000 NA ## ITEM_DIC_6 1 1.000 1.000 1.000 1.000 ## ITEM_DIC_7 1 1.000 1.000 1.000 1.000 ## ITEM_DIC_6 ITEM_DIC_7 ## ITEM_DIC_1 0.044 0.126 ## ITEM_DIC_2 0.477 0.939 ## ITEM_DIC_3 0.000 0.779 ## ITEM_DIC_4 0.130 0.102 ## ITEM_DIC_5 0.063 0.411 ## ITEM_DIC_6 NA 0.003 ## ITEM_DIC_7 1.000 NA ## ## LD matrix (lower triangle) and standardized values. ## ## Upper triangle summary: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.201 -0.040 0.006 0.005 0.076 0.150 ## ## ITEM_DIC_1 ITEM_DIC_2 ITEM_DIC_3 ITEM_DIC_4 ITEM_DIC_5 ## ITEM_DIC_1 NA 0.037 0.013 0.150 0.006 ## ITEM_DIC_2 0.581 NA 0.060 0.076 -0.012 ## ITEM_DIC_3 0.069 1.516 NA 0.109 0.078 ## ITEM_DIC_4 9.455 2.398 4.938 NA 0.128 ## ITEM_DIC_5 0.013 0.056 2.556 6.798 NA ## ITEM_DIC_6 4.048 0.506 16.942 2.295 3.444 ## ITEM_DIC_7 2.336 0.006 0.079 2.672 0.676 ## ITEM_DIC_6 ITEM_DIC_7 ## ITEM_DIC_1 -0.098 0.075 ## ITEM_DIC_2 -0.035 -0.004 ## ITEM_DIC_3 -0.201 -0.014 ## ITEM_DIC_4 -0.074 0.080 ## ITEM_DIC_5 -0.091 -0.040 ## ITEM_DIC_6 NA -0.147 ## ITEM_DIC_7 9.044 NA Nei risultati compariranno due matrici. Nella prima matrice sono indicati i p-value (diagononale superiore) e i gradi di libertà (diagonale inferiore). Nella seconda matrice sono riportati i valori del Chi-Quadro per ogni coppia di item (diagonale inferiore) e la correlazione fra i residui standardizzati (diagnonale superiore). I valori dei p values minori di .01 (Chen &amp; Thissen, 1997) indicano la presenza di dipendenza locale fra la coppia di item. Maggiore è il numero di p-values significativi più è alta la probabilità che la scala non sia unidimensionale. Per unulteriore approfondimento, si possono anche guardare le correlazioni fra i residui standardizzati. Per questi, non cè un valore soglia, ma più basse sono meglio è. Per concludere con le assunzioni, è possibile anche verificare le saturazioni degli item sul fattore con la funzione summary(). summary(MOD.1PL) #Saturazioni 1PL ## F1 h2 ## ITEM_DIC_1 0.675 0.455 ## ITEM_DIC_2 0.675 0.455 ## ITEM_DIC_3 0.675 0.455 ## ITEM_DIC_4 0.675 0.455 ## ITEM_DIC_5 0.675 0.455 ## ITEM_DIC_6 0.675 0.455 ## ITEM_DIC_7 0.675 0.455 ## ## SS loadings: 3.188 ## Proportion Var: 0.455 ## ## Factor correlations: ## ## F1 ## F1 1 Calibrazione modello 2PL Procediamo ora alla calibrazione del modello 2PL. Impostiamo la struttura fattoriale, obbligando gli item a saturare sullo stesso fattore (F1) per poi procedere alla calibrazione del modello tramite la funzione mirt(). #Struttura fattoriale del modello 2PL fct.str.2PL &lt;- mirt.model(&#39;F1 = 1-7&#39;) #Calibrazione del modello 2PL MOD.2PL &lt;- mirt(data=TEST.DIC.item, model=fct.str.2PL, itemtype = &quot;2PL&quot;) ## Iteration: 1, Log-Lik: -1606.401, Max-Change: 0.60800 Iteration: 2, Log-Lik: -1565.328, Max-Change: 0.46610 Iteration: 3, Log-Lik: -1552.379, Max-Change: 0.28807 Iteration: 4, Log-Lik: -1548.487, Max-Change: 0.22631 Iteration: 5, Log-Lik: -1547.108, Max-Change: 0.14802 Iteration: 6, Log-Lik: -1546.615, Max-Change: 0.10566 Iteration: 7, Log-Lik: -1546.359, Max-Change: 0.06230 Iteration: 8, Log-Lik: -1546.304, Max-Change: 0.04476 Iteration: 9, Log-Lik: -1546.278, Max-Change: 0.03207 Iteration: 10, Log-Lik: -1546.256, Max-Change: 0.01015 Iteration: 11, Log-Lik: -1546.255, Max-Change: 0.00878 Iteration: 12, Log-Lik: -1546.254, Max-Change: 0.00500 Iteration: 13, Log-Lik: -1546.254, Max-Change: 0.00220 Iteration: 14, Log-Lik: -1546.254, Max-Change: 0.00109 Iteration: 15, Log-Lik: -1546.254, Max-Change: 0.00096 Iteration: 16, Log-Lik: -1546.254, Max-Change: 0.00078 Iteration: 17, Log-Lik: -1546.254, Max-Change: 0.00019 Iteration: 18, Log-Lik: -1546.254, Max-Change: 0.00070 Iteration: 19, Log-Lik: -1546.254, Max-Change: 0.00026 Iteration: 20, Log-Lik: -1546.254, Max-Change: 0.00011 Iteration: 21, Log-Lik: -1546.254, Max-Change: 0.00051 Iteration: 22, Log-Lik: -1546.254, Max-Change: 0.00013 Iteration: 23, Log-Lik: -1546.254, Max-Change: 0.00043 Iteration: 24, Log-Lik: -1546.254, Max-Change: 0.00011 Iteration: 25, Log-Lik: -1546.254, Max-Change: 0.00009 Verifichiamo poi leventuale presenza di Dipendenza Locale nel modello 2PL e osserviamo le saturazioni. #Assunzoni 2PL residuals(MOD.2PL,type=&#39;LD&#39;,df.p=TRUE) #LD per il modello 2PL ## Degrees of freedom (lower triangle) and p-values: ## ## ITEM_DIC_1 ITEM_DIC_2 ITEM_DIC_3 ITEM_DIC_4 ITEM_DIC_5 ## ITEM_DIC_1 NA 0.967 0.643 0.760 0.405 ## ITEM_DIC_2 1 NA 0.416 0.805 0.455 ## ITEM_DIC_3 1 1.000 NA 0.886 0.238 ## ITEM_DIC_4 1 1.000 1.000 NA 0.508 ## ITEM_DIC_5 1 1.000 1.000 1.000 NA ## ITEM_DIC_6 1 1.000 1.000 1.000 1.000 ## ITEM_DIC_7 1 1.000 1.000 1.000 1.000 ## ITEM_DIC_6 ITEM_DIC_7 ## ITEM_DIC_1 0.625 0.177 ## ITEM_DIC_2 0.289 0.959 ## ITEM_DIC_3 0.187 0.913 ## ITEM_DIC_4 0.721 0.856 ## ITEM_DIC_5 0.687 0.351 ## ITEM_DIC_6 NA 0.923 ## ITEM_DIC_7 1.000 NA ## ## LD matrix (lower triangle) and standardized values. ## ## Upper triangle summary: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.064 -0.012 0.007 0.005 0.024 0.066 ## ## ITEM_DIC_1 ITEM_DIC_2 ITEM_DIC_3 ITEM_DIC_4 ITEM_DIC_5 ## ITEM_DIC_1 NA 0.002 -0.023 0.015 -0.041 ## ITEM_DIC_2 0.002 NA 0.040 -0.012 -0.037 ## ITEM_DIC_3 0.214 0.661 NA 0.007 0.058 ## ITEM_DIC_4 0.093 0.061 0.021 NA 0.032 ## ITEM_DIC_5 0.695 0.559 1.394 0.438 NA ## ITEM_DIC_6 0.239 1.124 1.737 0.128 0.163 ## ITEM_DIC_7 1.821 0.003 0.012 0.033 0.869 ## ITEM_DIC_6 ITEM_DIC_7 ## ITEM_DIC_1 0.024 0.066 ## ITEM_DIC_2 0.052 -0.003 ## ITEM_DIC_3 -0.064 -0.005 ## ITEM_DIC_4 0.017 0.009 ## ITEM_DIC_5 0.020 -0.046 ## ITEM_DIC_6 NA -0.005 ## ITEM_DIC_7 0.009 NA summary(MOD.2PL) #Saturazioni 2PL ## F1 h2 ## ITEM_DIC_1 0.731 0.535 ## ITEM_DIC_2 0.709 0.503 ## ITEM_DIC_3 0.691 0.477 ## ITEM_DIC_4 0.866 0.750 ## ITEM_DIC_5 0.721 0.521 ## ITEM_DIC_6 0.370 0.137 ## ITEM_DIC_7 0.641 0.410 ## ## SS loadings: 3.333 ## Proportion Var: 0.476 ## ## Factor correlations: ## ## F1 ## F1 1 Confronto fra modelli Il confronto fra modelli è una prassi non obbligatoria ma sicuramente utile per riuscire a scegliere il modello con il miglior equilibrio tra capacità esplicativa e parsimoniosità. Il confronto fra modelli può essere effettuato con la funzione anova(). anova(MOD.1PL, MOD.2PL) ## AIC SABIC HQ BIC logLik X2 df p ## MOD.1PL 3149.823 3156.721 3162.586 3182.107 -1566.912 ## MOD.2PL 3120.508 3132.579 3142.842 3177.004 -1546.254 41.316 6 0 Per il TEST.DIC emerge una differenza significativa (p &lt; .001) tra i modelli 2PL e 1PL, ad indicare che è necessario proseguire con il modello meno parsimonioso, pena la significativa perdita di informazione. Questa conclusione è suffragata anche dagli indici AIC e BIC, migliori per il modello 2PL. Fit del modello e degli item Dopo aver scelto il modello proseguiamo con il fit della scala e il fit degli item nel modello 2PL. Per il fit della scala, chiamato anche fit globale, si utilizzano una famiglia di indici derivti dal Chi-Quadrto. Il primo a comparire è stato lindice \\(M_2\\) e il corrispettivo \\(RMSEA_2\\) (Maydeu -Olivares, &amp; Joe, 2006; Maydeu-Olivares, &amp; Joe, 2014). Negli anni, sono state proposte diverse modifiche dellindice \\(M_2\\). Nellesempio sottostante, utilizzeremo una variante denominata \\(M_2*\\) (Cai, &amp; Hansen, 2013), la quale è una generalizzazione dellindice \\(M_2\\) che risulta avere un miglior funzionamento e una maggior applicabilità. M2(MOD.2PL,type = &#39;M2*&#39;) #Fit Globale 2PL ## M2 df p RMSEA RMSEA_5 RMSEA_95 SRMSR ## stats 14.35488 14 0.4236208 0.00779666 0 0.0482613 0.02929834 ## TLI CFI ## stats 0.9991766 0.999451 Si prosegue poi con la verifica del fit di ogni singolo item utilizzando la statistica \\(S-X^2\\) (Orlando &amp; Thissen, 2000). Un valore di p maggiore di .01 è indicativo di un buon fit dellitem. itemfit(MOD.2PL, fit_stats = &quot;S_X2&quot;, na.rm = T) #fit degli item nel 2PL ## Data does not contain missing values. Continuing normally ## Sample size after row-wise response data removal: 418 ## item S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 ## 1 ITEM_DIC_1 1.434 4 0.000 0.838 ## 2 ITEM_DIC_2 5.319 3 0.043 0.150 ## 3 ITEM_DIC_3 5.784 4 0.033 0.216 ## 4 ITEM_DIC_4 6.675 3 0.054 0.083 ## 5 ITEM_DIC_5 3.855 3 0.026 0.278 ## 6 ITEM_DIC_6 7.954 4 0.049 0.093 ## 7 ITEM_DIC_7 7.110 4 0.043 0.130 Parametri degli item e Item Characteristic Curves (ICC) Proseguiamo analizzando i parametri degli item nel modello 2PL. Tramite la funzione coef() richiediamo i parametri del modello. Impostando IRTpars=TRUE, ottieniamo i parametri nella metrica classica, dove la location dellitem è indicata con il parametro denominato difficulty (b). Di default, mirt utilizerebbe unaltra metrica, rappresentando la location tramite il parametro d, denominato easiness, del quale il parametro b è una trasformazione, che ne semplifica la leggibilità. In termini formali: \\(b=-a/d\\). COEF.2PL&lt;-coef(MOD.2PL, IRTpars=TRUE, simplify=TRUE) COEF.2PL ## $items ## a b g u ## ITEM_DIC_1 1.826 0.257 0 1 ## ITEM_DIC_2 1.711 1.476 0 1 ## ITEM_DIC_3 1.626 0.668 0 1 ## ITEM_DIC_4 2.950 0.083 0 1 ## ITEM_DIC_5 1.773 -1.162 0 1 ## ITEM_DIC_6 0.677 -1.366 0 1 ## ITEM_DIC_7 1.420 0.634 0 1 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Tutti gli item dimostravano una capacità discriminativa (a) eccellente, ad ecezione dellitem 6, il quale risultava avere una capacità discriminiativa moderata e litem 7 che risultava avere una capacità discriminativa alta (Baker, 2001). Per quanto riguarda la location, tutti gli item risultavano essere collacati fra -1.34 e 1.47 ad indicare che il test risultava misurare i livelli medi di tratto. Con la funzione itemplot() è possibile ottenere le ICC degli item. Largomento item=permette di selezionare litem da stampare in console. itemplot(MOD.2PL,type = &#39;trace&#39;, item =1) #ICC del primo item Se si desidera ottenere tutte le ICC degli item del test con un solo comando, si può utilizzare un ciclo for(). # Stampa di tutte le ICC del test for(i in 1:extract.mirt(MOD.2PL, &quot;nitems&quot;)) {plot(MOD.2PL, type = &#39;trace&#39;, which.items = i, facet_items=TRUE, theta_lim = c(-3, 3))} %&gt;% print() Capacità informativa del test, Item Information Functions (IIFs) e Test Information Function (TIF) Come ultimo aspetto della calibrazione, è possibile verificare linformazione apportata da ogni singolo item e linformazione complessiva del test. Linformazione apportata da ogni singolo item può essere visualizzata tramite le IIF di ogni singolo item, tramite il comando itemplot() e impostando largomento type ='info' . itemplot(MOD.2PL,type =&#39;info&#39;, item =1) #IIF del primo item Se si desidera ottenere tutte le IIF degli item del test con un solo comando, si può utilizzare un ciclo for(): #IIF for (i in 1:extract.mirt(MOD.2PL, &quot;nitems&quot;)) {plot(MOD.2PL, type = &#39;infotrace&#39;, which.items = i, facet_items=TRUE, theta_lim = c(-3, 3))} %&gt;% print() Per ottenere, invece, la TIF e lerrore di misura, va utilizzata la funzione plot(), inserendo largomento type = 'infoSE'. plot(MOD.2PL, type = &#39;infoSE&#39;, which.items = 1:extract.mirt(MOD.2PL, &quot;nitems&quot;), theta_lim = c(-3, 3)) "],["differential-item-functioning-per-modelli-dicotomici.html", "Differential Item Functioning per modelli dicotomici", " Differential Item Functioning per modelli dicotomici Allinterno del framework dellItem Response Theory (IRT) è anche possibile studiare linvarianza di una scala a livello dellItem, tramite la procedura del Differential Item Functioning (DIF). Esitono diversi approcci al DIF, fra i quali il metodo Mantzel-Haenszel (Mantzel, &amp; Haenszel, 1959; Holland, &amp; Thayer,1988), la regressione logistica (Swaminathan, &amp; Rogers, 1990) e il Likelihood Ratio Test (Thissen et al., 1988). Di seguito approfondiremo questultimo. Per illustrare il DIF utilizzeremo il database TEST.DIC. Condurremo lo studio dellinvarianza di genere utilizzando la variabile sex (1=male; 2=female). Per prima cosa selezioniamo la variabile gruppo. GRUPPO&lt;-as.factor(TEST.DIC$sex) #var. gruppo Selezioniamo poi gli item sui quali condurre linvarianza. item.DIF&lt;-TEST.DIC[,3:9] #item per DIF Definiamo poi la struttura fattoriale, come già fatto in precedenza. fct.str.DIF &lt;- mirt.model(&#39;F1 = 1-7&#39;) Infine, creiamo un oggetto contenente il tipo di modello, per non doverlo inserire in ogni passaggio. tipo.mod&lt;-&#39;2PL&#39; Stima dei parametri nei due gruppi Procediamo alla stima dei parametri degli item nel gruppo di maschi (GRUPPO==1). mod.group1&lt;-filter(item.DIF, GRUPPO==&#39;1&#39;)%&gt;% #inserire etichetta primo gruppo mirt(model=fct.str.DIF, itemtype = tipo.mod) #es: GRUPPO == &#39;1&#39; ## Iteration: 1, Log-Lik: -843.738, Max-Change: 0.61586 Iteration: 2, Log-Lik: -821.640, Max-Change: 0.44042 Iteration: 3, Log-Lik: -814.473, Max-Change: 0.28525 Iteration: 4, Log-Lik: -812.296, Max-Change: 0.17850 Iteration: 5, Log-Lik: -811.599, Max-Change: 0.11333 Iteration: 6, Log-Lik: -811.361, Max-Change: 0.07228 Iteration: 7, Log-Lik: -811.248, Max-Change: 0.03180 Iteration: 8, Log-Lik: -811.234, Max-Change: 0.02210 Iteration: 9, Log-Lik: -811.229, Max-Change: 0.01378 Iteration: 10, Log-Lik: -811.226, Max-Change: 0.00758 Iteration: 11, Log-Lik: -811.225, Max-Change: 0.00510 Iteration: 12, Log-Lik: -811.224, Max-Change: 0.00357 Iteration: 13, Log-Lik: -811.224, Max-Change: 0.00131 Iteration: 14, Log-Lik: -811.224, Max-Change: 0.00123 Iteration: 15, Log-Lik: -811.224, Max-Change: 0.00046 Iteration: 16, Log-Lik: -811.224, Max-Change: 0.00040 Iteration: 17, Log-Lik: -811.224, Max-Change: 0.00034 Iteration: 18, Log-Lik: -811.224, Max-Change: 0.00029 Iteration: 19, Log-Lik: -811.224, Max-Change: 0.00021 Iteration: 20, Log-Lik: -811.224, Max-Change: 0.00019 Iteration: 21, Log-Lik: -811.224, Max-Change: 0.00017 Iteration: 22, Log-Lik: -811.224, Max-Change: 0.00015 Iteration: 23, Log-Lik: -811.224, Max-Change: 0.00014 Iteration: 24, Log-Lik: -811.224, Max-Change: 0.00012 Iteration: 25, Log-Lik: -811.224, Max-Change: 0.00011 Iteration: 26, Log-Lik: -811.224, Max-Change: 0.00010 Iteration: 27, Log-Lik: -811.224, Max-Change: 0.00009 coef(mod.group1, simplify=TRUE, IRTpars=T) #stampa dei parametri ## $items ## a b g u ## ITEM_DIC_1 2.694 0.328 0 1 ## ITEM_DIC_2 1.583 1.532 0 1 ## ITEM_DIC_3 1.782 0.944 0 1 ## ITEM_DIC_4 2.165 0.234 0 1 ## ITEM_DIC_5 1.717 -1.063 0 1 ## ITEM_DIC_6 0.592 -1.879 0 1 ## ITEM_DIC_7 1.289 0.790 0 1 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Stimiamo poi i parametri nel gruppo delle femmine (GRUPPO==2). mod.group2&lt;-filter(item.DIF, GRUPPO==&#39;2&#39;)%&gt;% #inserire etichetta secondo gruppo mirt(model=fct.str.DIF, itemtype = tipo.mod) #es: GRUPPO == &#39;2&#39; ## Iteration: 1, Log-Lik: -694.990, Max-Change: 0.82420 Iteration: 2, Log-Lik: -674.419, Max-Change: 0.66239 Iteration: 3, Log-Lik: -667.961, Max-Change: 0.50617 Iteration: 4, Log-Lik: -665.768, Max-Change: 0.38798 Iteration: 5, Log-Lik: -664.889, Max-Change: 0.30633 Iteration: 6, Log-Lik: -664.484, Max-Change: 0.24955 Iteration: 7, Log-Lik: -664.024, Max-Change: 0.11400 Iteration: 8, Log-Lik: -663.991, Max-Change: 0.10336 Iteration: 9, Log-Lik: -663.968, Max-Change: 0.09343 Iteration: 10, Log-Lik: -663.906, Max-Change: 0.04630 Iteration: 11, Log-Lik: -663.902, Max-Change: 0.04024 Iteration: 12, Log-Lik: -663.900, Max-Change: 0.03196 Iteration: 13, Log-Lik: -663.895, Max-Change: 0.02119 Iteration: 14, Log-Lik: -663.895, Max-Change: 0.02255 Iteration: 15, Log-Lik: -663.894, Max-Change: 0.01832 Iteration: 16, Log-Lik: -663.892, Max-Change: 0.01618 Iteration: 17, Log-Lik: -663.892, Max-Change: 0.01486 Iteration: 18, Log-Lik: -663.892, Max-Change: 0.01147 Iteration: 19, Log-Lik: -663.891, Max-Change: 0.01189 Iteration: 20, Log-Lik: -663.891, Max-Change: 0.00638 Iteration: 21, Log-Lik: -663.891, Max-Change: 0.00039 Iteration: 22, Log-Lik: -663.891, Max-Change: 0.00039 Iteration: 23, Log-Lik: -663.891, Max-Change: 0.00538 Iteration: 24, Log-Lik: -663.891, Max-Change: 0.00185 Iteration: 25, Log-Lik: -663.891, Max-Change: 0.00036 Iteration: 26, Log-Lik: -663.891, Max-Change: 0.00183 Iteration: 27, Log-Lik: -663.891, Max-Change: 0.00538 Iteration: 28, Log-Lik: -663.891, Max-Change: 0.00040 Iteration: 29, Log-Lik: -663.891, Max-Change: 0.00166 Iteration: 30, Log-Lik: -663.891, Max-Change: 0.00485 Iteration: 31, Log-Lik: -663.891, Max-Change: 0.00034 Iteration: 32, Log-Lik: -663.891, Max-Change: 0.00030 Iteration: 33, Log-Lik: -663.891, Max-Change: 0.00416 Iteration: 34, Log-Lik: -663.891, Max-Change: 0.00144 Iteration: 35, Log-Lik: -663.891, Max-Change: 0.00075 Iteration: 36, Log-Lik: -663.891, Max-Change: 0.00030 Iteration: 37, Log-Lik: -663.891, Max-Change: 0.00028 Iteration: 38, Log-Lik: -663.891, Max-Change: 0.00141 Iteration: 39, Log-Lik: -663.891, Max-Change: 0.00040 Iteration: 40, Log-Lik: -663.891, Max-Change: 0.00028 Iteration: 41, Log-Lik: -663.891, Max-Change: 0.00138 Iteration: 42, Log-Lik: -663.891, Max-Change: 0.00049 Iteration: 43, Log-Lik: -663.891, Max-Change: 0.00027 Iteration: 44, Log-Lik: -663.891, Max-Change: 0.00135 Iteration: 45, Log-Lik: -663.891, Max-Change: 0.00056 Iteration: 46, Log-Lik: -663.891, Max-Change: 0.00027 Iteration: 47, Log-Lik: -663.891, Max-Change: 0.00132 Iteration: 48, Log-Lik: -663.891, Max-Change: 0.00058 Iteration: 49, Log-Lik: -663.891, Max-Change: 0.00026 Iteration: 50, Log-Lik: -663.891, Max-Change: 0.00129 Iteration: 51, Log-Lik: -663.891, Max-Change: 0.00058 Iteration: 52, Log-Lik: -663.891, Max-Change: 0.00025 Iteration: 53, Log-Lik: -663.891, Max-Change: 0.00126 Iteration: 54, Log-Lik: -663.891, Max-Change: 0.00058 Iteration: 55, Log-Lik: -663.891, Max-Change: 0.00025 Iteration: 56, Log-Lik: -663.891, Max-Change: 0.00124 Iteration: 57, Log-Lik: -663.891, Max-Change: 0.00057 Iteration: 58, Log-Lik: -663.891, Max-Change: 0.00024 Iteration: 59, Log-Lik: -663.891, Max-Change: 0.00121 Iteration: 60, Log-Lik: -663.891, Max-Change: 0.00056 Iteration: 61, Log-Lik: -663.891, Max-Change: 0.00024 Iteration: 62, Log-Lik: -663.891, Max-Change: 0.00118 Iteration: 63, Log-Lik: -663.891, Max-Change: 0.00055 Iteration: 64, Log-Lik: -663.891, Max-Change: 0.00023 Iteration: 65, Log-Lik: -663.891, Max-Change: 0.00116 Iteration: 66, Log-Lik: -663.891, Max-Change: 0.00054 Iteration: 67, Log-Lik: -663.891, Max-Change: 0.00023 Iteration: 68, Log-Lik: -663.891, Max-Change: 0.00113 Iteration: 69, Log-Lik: -663.891, Max-Change: 0.00053 Iteration: 70, Log-Lik: -663.891, Max-Change: 0.00022 Iteration: 71, Log-Lik: -663.891, Max-Change: 0.00111 Iteration: 72, Log-Lik: -663.891, Max-Change: 0.00052 Iteration: 73, Log-Lik: -663.891, Max-Change: 0.00022 Iteration: 74, Log-Lik: -663.891, Max-Change: 0.00109 Iteration: 75, Log-Lik: -663.891, Max-Change: 0.00051 Iteration: 76, Log-Lik: -663.891, Max-Change: 0.00021 Iteration: 77, Log-Lik: -663.891, Max-Change: 0.00106 Iteration: 78, Log-Lik: -663.891, Max-Change: 0.00049 Iteration: 79, Log-Lik: -663.891, Max-Change: 0.00021 Iteration: 80, Log-Lik: -663.891, Max-Change: 0.00104 Iteration: 81, Log-Lik: -663.891, Max-Change: 0.00048 Iteration: 82, Log-Lik: -663.891, Max-Change: 0.00021 Iteration: 83, Log-Lik: -663.891, Max-Change: 0.00102 Iteration: 84, Log-Lik: -663.891, Max-Change: 0.00047 Iteration: 85, Log-Lik: -663.891, Max-Change: 0.00020 Iteration: 86, Log-Lik: -663.891, Max-Change: 0.00100 Iteration: 87, Log-Lik: -663.891, Max-Change: 0.00046 Iteration: 88, Log-Lik: -663.891, Max-Change: 0.00020 Iteration: 89, Log-Lik: -663.891, Max-Change: 0.00098 Iteration: 90, Log-Lik: -663.891, Max-Change: 0.00045 Iteration: 91, Log-Lik: -663.891, Max-Change: 0.00019 Iteration: 92, Log-Lik: -663.891, Max-Change: 0.00096 Iteration: 93, Log-Lik: -663.891, Max-Change: 0.00045 Iteration: 94, Log-Lik: -663.891, Max-Change: 0.00019 Iteration: 95, Log-Lik: -663.891, Max-Change: 0.00094 Iteration: 96, Log-Lik: -663.891, Max-Change: 0.00044 Iteration: 97, Log-Lik: -663.891, Max-Change: 0.00018 Iteration: 98, Log-Lik: -663.891, Max-Change: 0.00092 Iteration: 99, Log-Lik: -663.891, Max-Change: 0.00043 Iteration: 100, Log-Lik: -663.891, Max-Change: 0.00018 Iteration: 101, Log-Lik: -663.891, Max-Change: 0.00090 Iteration: 102, Log-Lik: -663.891, Max-Change: 0.00042 Iteration: 103, Log-Lik: -663.891, Max-Change: 0.00018 Iteration: 104, Log-Lik: -663.891, Max-Change: 0.00088 Iteration: 105, Log-Lik: -663.891, Max-Change: 0.00041 Iteration: 106, Log-Lik: -663.891, Max-Change: 0.00017 Iteration: 107, Log-Lik: -663.891, Max-Change: 0.00086 Iteration: 108, Log-Lik: -663.891, Max-Change: 0.00040 Iteration: 109, Log-Lik: -663.891, Max-Change: 0.00017 Iteration: 110, Log-Lik: -663.891, Max-Change: 0.00084 Iteration: 111, Log-Lik: -663.891, Max-Change: 0.00039 Iteration: 112, Log-Lik: -663.891, Max-Change: 0.00017 Iteration: 113, Log-Lik: -663.891, Max-Change: 0.00083 Iteration: 114, Log-Lik: -663.891, Max-Change: 0.00038 Iteration: 115, Log-Lik: -663.891, Max-Change: 0.00016 Iteration: 116, Log-Lik: -663.891, Max-Change: 0.00081 Iteration: 117, Log-Lik: -663.891, Max-Change: 0.00038 Iteration: 118, Log-Lik: -663.891, Max-Change: 0.00016 Iteration: 119, Log-Lik: -663.891, Max-Change: 0.00079 Iteration: 120, Log-Lik: -663.891, Max-Change: 0.00037 Iteration: 121, Log-Lik: -663.891, Max-Change: 0.00016 Iteration: 122, Log-Lik: -663.891, Max-Change: 0.00078 Iteration: 123, Log-Lik: -663.891, Max-Change: 0.00036 Iteration: 124, Log-Lik: -663.891, Max-Change: 0.00015 Iteration: 125, Log-Lik: -663.891, Max-Change: 0.00076 Iteration: 126, Log-Lik: -663.891, Max-Change: 0.00035 Iteration: 127, Log-Lik: -663.891, Max-Change: 0.00015 Iteration: 128, Log-Lik: -663.891, Max-Change: 0.00074 Iteration: 129, Log-Lik: -663.891, Max-Change: 0.00035 Iteration: 130, Log-Lik: -663.891, Max-Change: 0.00015 Iteration: 131, Log-Lik: -663.891, Max-Change: 0.00073 Iteration: 132, Log-Lik: -663.891, Max-Change: 0.00034 Iteration: 133, Log-Lik: -663.891, Max-Change: 0.00014 Iteration: 134, Log-Lik: -663.891, Max-Change: 0.00071 Iteration: 135, Log-Lik: -663.891, Max-Change: 0.00033 Iteration: 136, Log-Lik: -663.891, Max-Change: 0.00014 Iteration: 137, Log-Lik: -663.891, Max-Change: 0.00070 Iteration: 138, Log-Lik: -663.891, Max-Change: 0.00032 Iteration: 139, Log-Lik: -663.891, Max-Change: 0.00014 Iteration: 140, Log-Lik: -663.891, Max-Change: 0.00068 Iteration: 141, Log-Lik: -663.891, Max-Change: 0.00032 Iteration: 142, Log-Lik: -663.891, Max-Change: 0.00014 Iteration: 143, Log-Lik: -663.891, Max-Change: 0.00067 Iteration: 144, Log-Lik: -663.891, Max-Change: 0.00031 Iteration: 145, Log-Lik: -663.891, Max-Change: 0.00013 Iteration: 146, Log-Lik: -663.891, Max-Change: 0.00066 Iteration: 147, Log-Lik: -663.891, Max-Change: 0.00031 Iteration: 148, Log-Lik: -663.891, Max-Change: 0.00013 Iteration: 149, Log-Lik: -663.891, Max-Change: 0.00064 Iteration: 150, Log-Lik: -663.891, Max-Change: 0.00030 Iteration: 151, Log-Lik: -663.891, Max-Change: 0.00013 Iteration: 152, Log-Lik: -663.891, Max-Change: 0.00063 Iteration: 153, Log-Lik: -663.891, Max-Change: 0.00029 Iteration: 154, Log-Lik: -663.891, Max-Change: 0.00012 Iteration: 155, Log-Lik: -663.891, Max-Change: 0.00062 Iteration: 156, Log-Lik: -663.891, Max-Change: 0.00029 Iteration: 157, Log-Lik: -663.891, Max-Change: 0.00012 Iteration: 158, Log-Lik: -663.891, Max-Change: 0.00061 Iteration: 159, Log-Lik: -663.891, Max-Change: 0.00028 Iteration: 160, Log-Lik: -663.891, Max-Change: 0.00012 Iteration: 161, Log-Lik: -663.891, Max-Change: 0.00059 Iteration: 162, Log-Lik: -663.891, Max-Change: 0.00028 Iteration: 163, Log-Lik: -663.891, Max-Change: 0.00012 Iteration: 164, Log-Lik: -663.891, Max-Change: 0.00058 Iteration: 165, Log-Lik: -663.891, Max-Change: 0.00027 Iteration: 166, Log-Lik: -663.891, Max-Change: 0.00011 Iteration: 167, Log-Lik: -663.891, Max-Change: 0.00057 Iteration: 168, Log-Lik: -663.891, Max-Change: 0.00026 Iteration: 169, Log-Lik: -663.891, Max-Change: 0.00011 Iteration: 170, Log-Lik: -663.891, Max-Change: 0.00056 Iteration: 171, Log-Lik: -663.891, Max-Change: 0.00026 Iteration: 172, Log-Lik: -663.891, Max-Change: 0.00011 Iteration: 173, Log-Lik: -663.891, Max-Change: 0.00055 Iteration: 174, Log-Lik: -663.891, Max-Change: 0.00025 Iteration: 175, Log-Lik: -663.891, Max-Change: 0.00011 Iteration: 176, Log-Lik: -663.891, Max-Change: 0.00054 Iteration: 177, Log-Lik: -663.891, Max-Change: 0.00025 Iteration: 178, Log-Lik: -663.891, Max-Change: 0.00011 Iteration: 179, Log-Lik: -663.891, Max-Change: 0.00052 Iteration: 180, Log-Lik: -663.891, Max-Change: 0.00024 Iteration: 181, Log-Lik: -663.891, Max-Change: 0.00010 Iteration: 182, Log-Lik: -663.891, Max-Change: 0.00051 Iteration: 183, Log-Lik: -663.891, Max-Change: 0.00024 Iteration: 184, Log-Lik: -663.891, Max-Change: 0.00010 Iteration: 185, Log-Lik: -663.891, Max-Change: 0.00050 Iteration: 186, Log-Lik: -663.891, Max-Change: 0.00023 Iteration: 187, Log-Lik: -663.891, Max-Change: 0.00010 coef(mod.group2, simplify=TRUE, IRTpars=T) #stampa dei parametri ## $items ## a b g u ## ITEM_DIC_1 1.296 0.102 0 1 ## ITEM_DIC_2 2.488 1.273 0 1 ## ITEM_DIC_3 1.366 0.347 0 1 ## ITEM_DIC_4 5.669 -0.074 0 1 ## ITEM_DIC_5 1.653 -1.398 0 1 ## ITEM_DIC_6 1.020 -0.671 0 1 ## ITEM_DIC_7 1.437 0.541 0 1 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Primo step della procedura di purificazione Il primo step della procedura di purificazione prevede di stimare un modello di partenza dove tutti i parametri degli item sono vincolati ad essere uguali nei due gruppi. Inoltre, le medie e le varianze vengono fissate a 0 e 1 nel primo gruppo (gruppo di riferimento) e lasciate libere di essere stimate nel secondo gruppo (gruppo focale). La funzione che permette di creare questo modello è denominata multiplegroup(). Largomento invariance() permette di impostare i vincoli sopra esposti. Tramite colnames(item.DIF) imponiamo i vincoli ai parametri degl item, mentre tramite 'free_means' e 'free_var' impostiamo i vincoli alle medie e alle varianze. mod.dif.1&lt;- multipleGroup(item.DIF,model= fct.str.DIF, itemtype = tipo.mod, group =GRUPPO,SE=TRUE, invariance = c(colnames(item.DIF), &#39;free_means&#39;, &#39;free_var&#39;)) ## NA values in group removed, along with associated rows in data ## Iteration: 1, Log-Lik: -1552.108, Max-Change: 0.60151 Iteration: 2, Log-Lik: -1506.706, Max-Change: 0.41758 Iteration: 3, Log-Lik: -1496.243, Max-Change: 0.26373 Iteration: 4, Log-Lik: -1493.722, Max-Change: 0.17436 Iteration: 5, Log-Lik: -1492.739, Max-Change: 0.12205 Iteration: 6, Log-Lik: -1492.193, Max-Change: 0.08904 Iteration: 7, Log-Lik: -1491.607, Max-Change: 0.06614 Iteration: 8, Log-Lik: -1491.381, Max-Change: 0.03897 Iteration: 9, Log-Lik: -1491.272, Max-Change: 0.02826 Iteration: 10, Log-Lik: -1491.162, Max-Change: 0.03725 Iteration: 11, Log-Lik: -1491.086, Max-Change: 0.02077 Iteration: 12, Log-Lik: -1491.056, Max-Change: 0.01477 Iteration: 13, Log-Lik: -1491.028, Max-Change: 0.01621 Iteration: 14, Log-Lik: -1491.012, Max-Change: 0.01041 Iteration: 15, Log-Lik: -1491.003, Max-Change: 0.00799 Iteration: 16, Log-Lik: -1490.997, Max-Change: 0.01339 Iteration: 17, Log-Lik: -1490.985, Max-Change: 0.00666 Iteration: 18, Log-Lik: -1490.983, Max-Change: 0.00439 Iteration: 19, Log-Lik: -1490.981, Max-Change: 0.00353 Iteration: 20, Log-Lik: -1490.980, Max-Change: 0.00279 Iteration: 21, Log-Lik: -1490.979, Max-Change: 0.00234 Iteration: 22, Log-Lik: -1490.979, Max-Change: 0.00461 Iteration: 23, Log-Lik: -1490.977, Max-Change: 0.00217 Iteration: 24, Log-Lik: -1490.977, Max-Change: 0.00137 Iteration: 25, Log-Lik: -1490.977, Max-Change: 0.00101 Iteration: 26, Log-Lik: -1490.976, Max-Change: 0.00083 Iteration: 27, Log-Lik: -1490.976, Max-Change: 0.00070 Iteration: 28, Log-Lik: -1490.976, Max-Change: 0.00141 Iteration: 29, Log-Lik: -1490.976, Max-Change: 0.00067 Iteration: 30, Log-Lik: -1490.976, Max-Change: 0.00043 Iteration: 31, Log-Lik: -1490.976, Max-Change: 0.00032 Iteration: 32, Log-Lik: -1490.976, Max-Change: 0.00026 Iteration: 33, Log-Lik: -1490.976, Max-Change: 0.00022 Iteration: 34, Log-Lik: -1490.976, Max-Change: 0.00046 Iteration: 35, Log-Lik: -1490.976, Max-Change: 0.00021 Iteration: 36, Log-Lik: -1490.976, Max-Change: 0.00013 Iteration: 37, Log-Lik: -1490.976, Max-Change: 0.00010 ## ## Calculating information matrix... A partire da questo modello, è possibile stimare il DIF al primo step di interazione tramite la funzione DIF(). Impostando la voce scheme=drop, procediamo rimuovendo i vincoli degli item uno ad uno per essere confrontati tramite il Chi-Quadro nei due gruppi. La stima del DIF viene eseguita prima nei parametri relativi alla capacità discriminativa (a), inserendo la voce which.par = 'a1' (Il parametro a è indicato sempre come a1 in mirt). DIF(mod.dif.1,which.par = &#39;a1&#39;, simplify = TRUE, scheme = &#39;drop&#39;) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_DIC_1 TRUE -2.398 -1.570 -0.814 1.603 4.398 1 0.036 ## ITEM_DIC_2 TRUE 1.058 1.886 2.642 5.059 0.942 1 0.332 ## ITEM_DIC_3 TRUE 0.876 1.705 2.460 4.878 1.124 1 0.289 ## ITEM_DIC_4 TRUE -0.730 0.099 0.854 3.272 2.73 1 0.099 ## ITEM_DIC_5 TRUE 1.756 2.584 3.340 5.757 0.244 1 0.621 ## ITEM_DIC_6 TRUE -0.528 0.301 1.056 3.474 2.528 1 0.112 ## ITEM_DIC_7 TRUE 1.874 2.703 3.458 5.876 0.126 1 0.723 Per proseguire poi con la stima del DIF relativo alla location. In questo caso, in which.par inseriremo il parametro d (easiness) e non b, poiché è il parametro di default utilizzato da mirt per la location. DIF(mod.dif.1,which.par = &#39;d&#39;, simplify = TRUE, scheme = &#39;drop&#39;) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_DIC_1 TRUE 1.992 2.820 3.576 5.993 0.008 1 0.929 ## ITEM_DIC_2 TRUE -1.055 -0.226 0.529 2.947 3.055 1 0.081 ## ITEM_DIC_3 TRUE -5.016 -4.188 -3.432 -1.015 7.016 1 0.008 ## ITEM_DIC_4 TRUE 1.982 2.810 3.566 5.983 0.018 1 0.893 ## ITEM_DIC_5 TRUE 1.809 2.637 3.393 5.810 0.191 1 0.662 ## ITEM_DIC_6 TRUE -7.690 -6.862 -6.106 -3.689 9.69 1 0.002 ## ITEM_DIC_7 TRUE 1.763 2.591 3.347 5.764 0.237 1 0.626 Utilizzando come criterio p&lt;.01, nessun item mostrava DIF in a. In b, invece, sia litem 3 (\\(X^2\\)(1)=6.49 , p = .008) che litem 6 (\\(X^2\\)(1)=10.32 , p &lt; .001) risultavano avere un valore di p associato minore della soglia fissata . Secondo step della procedura di purificazione Il secondo step della procedura di purificazione serve per verificare leffettiva presenza di DIF negli item che hanno manifestato DIF al primo step. Gli item senza DIF sono denominati item ancora e vengono fissati uguali nei due gruppi. Definiamo quindi un oggetto che contenga gli item ancora. In questo caso, gli item ancora sono il primo, il secondo, il quarto e il quinto. Li inseriremo usando la loro posizione ordinale nelloggetto denominato item.ancora. #Definisco gli item ancora itemnames &lt;- colnames(item.DIF) item.ancora&lt;- itemnames[c(1,2,4,5,7)] #Inserire gli item ancora print(item.ancora) ## [1] &quot;ITEM_DIC_1&quot; &quot;ITEM_DIC_2&quot; &quot;ITEM_DIC_4&quot; &quot;ITEM_DIC_5&quot; &quot;ITEM_DIC_7&quot; Proseguiamo poi creando un oggetto che contenga gli item candidati, ovvero gli item che saranno lasciati liberi di variare nei due gruppi per verificare leventuale presenza di DIF. #Definisco gi item da testare (candidati) item.candidati&lt;- c(3,6) #Inserire gli item candidati print(item.candidati) ## [1] 3 6 Ora dobbiamo creare un nuovo modello tramite la funzione multiplegroup() con i seguenti vincoli allinterno dellargomento invariance=c(): i parametri degli item ancora fissati ad essere uguali nei due gruppi; le medie e le varianze fissate a 0 e 1 nel gruppo di rifermineto e libere di essere stimate nel gruppo focale. mod.dif.2&lt;-multipleGroup(item.DIF,model= fct.str.DIF, itemtype = tipo.mod, group =GRUPPO,SE=TRUE, invariance = c(item.ancora, &#39;free_means&#39;, &#39;free_var&#39;)) ## NA values in group removed, along with associated rows in data ## Iteration: 1, Log-Lik: -1552.108, Max-Change: 0.60151 Iteration: 2, Log-Lik: -1497.920, Max-Change: 0.41784 Iteration: 3, Log-Lik: -1487.696, Max-Change: 0.26985 Iteration: 4, Log-Lik: -1485.040, Max-Change: 0.18088 Iteration: 5, Log-Lik: -1483.998, Max-Change: 0.12779 Iteration: 6, Log-Lik: -1483.422, Max-Change: 0.09438 Iteration: 7, Log-Lik: -1482.794, Max-Change: 0.07145 Iteration: 8, Log-Lik: -1482.523, Max-Change: 0.04190 Iteration: 9, Log-Lik: -1482.379, Max-Change: 0.03181 Iteration: 10, Log-Lik: -1482.246, Max-Change: 0.05183 Iteration: 11, Log-Lik: -1482.087, Max-Change: 0.02505 Iteration: 12, Log-Lik: -1482.040, Max-Change: 0.01766 Iteration: 13, Log-Lik: -1481.997, Max-Change: 0.01905 Iteration: 14, Log-Lik: -1481.970, Max-Change: 0.01276 Iteration: 15, Log-Lik: -1481.952, Max-Change: 0.01035 Iteration: 16, Log-Lik: -1481.944, Max-Change: 0.02110 Iteration: 17, Log-Lik: -1481.911, Max-Change: 0.00927 Iteration: 18, Log-Lik: -1481.904, Max-Change: 0.00612 Iteration: 19, Log-Lik: -1481.899, Max-Change: 0.00509 Iteration: 20, Log-Lik: -1481.896, Max-Change: 0.00414 Iteration: 21, Log-Lik: -1481.894, Max-Change: 0.00358 Iteration: 22, Log-Lik: -1481.893, Max-Change: 0.00767 Iteration: 23, Log-Lik: -1481.888, Max-Change: 0.00340 Iteration: 24, Log-Lik: -1481.887, Max-Change: 0.00225 Iteration: 25, Log-Lik: -1481.887, Max-Change: 0.00184 Iteration: 26, Log-Lik: -1481.886, Max-Change: 0.00152 Iteration: 27, Log-Lik: -1481.886, Max-Change: 0.00132 Iteration: 28, Log-Lik: -1481.886, Max-Change: 0.00285 Iteration: 29, Log-Lik: -1481.885, Max-Change: 0.00127 Iteration: 30, Log-Lik: -1481.885, Max-Change: 0.00084 Iteration: 31, Log-Lik: -1481.885, Max-Change: 0.00069 Iteration: 32, Log-Lik: -1481.885, Max-Change: 0.00058 Iteration: 33, Log-Lik: -1481.885, Max-Change: 0.00050 Iteration: 34, Log-Lik: -1481.885, Max-Change: 0.00108 Iteration: 35, Log-Lik: -1481.885, Max-Change: 0.00049 Iteration: 36, Log-Lik: -1481.885, Max-Change: 0.00032 Iteration: 37, Log-Lik: -1481.884, Max-Change: 0.00027 Iteration: 38, Log-Lik: -1481.884, Max-Change: 0.00022 Iteration: 39, Log-Lik: -1481.884, Max-Change: 0.00019 Iteration: 40, Log-Lik: -1481.884, Max-Change: 0.00042 Iteration: 41, Log-Lik: -1481.884, Max-Change: 0.00019 Iteration: 42, Log-Lik: -1481.884, Max-Change: 0.00012 Iteration: 43, Log-Lik: -1481.884, Max-Change: 0.00011 Iteration: 44, Log-Lik: -1481.884, Max-Change: 0.00009 ## ## Calculating information matrix... Procediamo poi con la stima del DIF. In questo caso, useremo lo schema add in cui i parametri degli item vengono confrontati fra i due gruppi uno alla volta per poi essere vincolati e procedere con il seguente parametro. Come prima, analizziamo il DIF in a. #DIF in a al secondo step di purificazione DIF(mod.dif.2,which.par = &#39;a1&#39;, simplify = TRUE, scheme = &#39;add&#39;, items2test = item.candidati) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_DIC_3 TRUE 1.576 2.404 3.160 5.577 0.424 1 0.515 ## ITEM_DIC_6 TRUE 0.124 0.953 1.708 4.126 1.876 1 0.171 Per poi proseguire analizzando il DIF in b. #DIF in b (d) al secondo step di purificazione DIF(mod.dif.2,which.par = &#39;d&#39;, simplify = TRUE, scheme = &#39;add&#39;, items2test = item.candidati) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_DIC_3 TRUE -3.502 -2.674 -1.918 0.499 5.502 1 0.019 ## ITEM_DIC_6 TRUE -5.431 -4.603 -3.847 -1.430 7.431 1 0.006 Al secondo step di purificazione, solo litem 6 risultava avere DIF nel parametro b (\\(X^2\\)(1)=7.43 , p &lt; .01), ad indicare che litem era invariante per genere, poiché risultava essere più facile per i maschi (b=-1.02) rispetto alle femmine (b=-.59). Questo può essere anche analizzato graficamente tramite la funzione itemplot() e inserendo nellargomento item= la posizione ordinale dellitem che si desidera visualizzare. itemplot(mod.dif.2, item=6, #Inserire l&#39; item da visualizzare type=&#39;trace&#39;, theta_lim = c(-3, 3)) Effect size del DIF Come ultimo aspetto, è possibile studiare leffect size del DIF utilizzando la procedura proposta da Meade (2010). Effect size a livello di item In primo luogo si valuta leffect size a livello di item tramite la funzione empirical_ES(). #Effect size al livello degli item #Indici empirical_ES(mod.dif.2) ## SIDS UIDS SIDN UIDN ESSD theta.of.max.D max.D ## item.1 0.000 0.000 0.000 0.000 0.000 -1.260 0.000 ## item.2 0.000 0.000 0.000 0.000 0.000 -1.260 0.000 ## item.3 0.113 0.113 0.107 0.107 0.465 0.429 0.161 ## item.4 0.000 0.000 0.000 0.000 0.000 -1.260 0.000 ## item.5 0.000 0.000 0.000 0.000 0.000 -1.260 0.000 ## item.6 -0.124 0.125 -0.125 0.128 -0.929 -1.260 -0.299 ## item.7 0.000 0.000 0.000 0.000 0.000 -1.260 0.000 ## mean.ES.foc mean.ES.ref ## item.1 0.466 0.466 ## item.2 0.157 0.157 ## item.3 0.409 0.297 ## item.4 0.516 0.516 ## item.5 0.842 0.842 ## item.6 0.641 0.765 ## item.7 0.362 0.362 #Grafici empirical_ES(mod.dif.2, plot = TRUE) Fra gli indici più utilizzati per lo studio del DIF vi sono i seguenti (Per unanalisi approdondita degli indici di Effect Size, consultare la guida di Meade). Signed Item Difference in the Sample (SIDIS) Rappresenta la differenza media, nella metrica dellitem, della differenza fra i due gruppi. Unsigned Item Difference in the Sample (UIDIS) Rappresenta la differenza media, nella metrica dellitem, della differenza fra i due gruppi in valore assoluto. Il valore assoluto permette di osservare la differenza media impedendo leffetto cancellazione lungo il tratto di theta. Utile è un confronto fra gli indici SIDIS e UIDIS. Se sono uguali, il DIF è di natura uniforme, quindi un gruppo ha livelli più alti dellaltro gruppo lungo tutto il continuum di theta (DIF uniforme). Se UIDIS è maggiore di SIDIS allora cè effetto cancellazione lungo il continuum di theta, ad indicare che un gruppo non ha sempre punteggi più alti dellaltro (DIF non uniforme) e va analizzato il grafico per comprendere in quale regione di theta è presente il DIF. Expected score standardized difference (ESSD) Rappresenta la differenza fra la media degli Espected Score del primo gruppo con quelli del secondo gruppo, divisi per la deviazione standard della distribuzione. Si interpreta con i criteri del d di Cohen (1988) . Effect size a livello di test Per valutare limpatto complessvo del DIF sulla scala, possiamo utilizzare degli indici forniti sempre da Meade (2010). Useremo, come sopra, la funzione empirical_ES(), introducendo però la voce DIF=FALSE. #Effect size al livello del test #ndici empirical_ES(mod.dif.2, DIF = FALSE) ## Effect Size Value ## 1 STDS -0.010939057 ## 2 UTDS 0.237892250 ## 3 UETSDS 0.092202120 ## 4 ETSSD -0.007087746 ## 5 Starks.DTFR -0.017710214 ## 6 UDTFR 0.235673763 ## 7 UETSDN 0.094939773 ## 8 theta.of.max.test.D -1.260153402 ## 9 Test.Dmax -0.251737668 #Grafici empirical_ES(mod.dif.2, DIF = FALSE, plot = TRUE) I tre indici presentati di seguito sono lapplicazione di quanto appena visto per litem a livello di test. Signed Test Difference in the Sample (STDIS) Differenza media, nella metrica del test, nella risposta fra i due gruppi. Unsigned Test Difference in the Sample (UTDIS) Differenza media, nella metrica del test, nella risposta fra i due gruppi senza leffetto cancellazione. Se messa in confronto con STIDS, è possibile cogliere la presenza di DIF uniforme/ non uniforme a livello di test. Expected test score standardized difference (ETSSD) Rappresenta la differenza fra la media degli Espected Test Score nei due gruppi, diviso per la deviazione standard. Si interpreta con i criteri del d di Cohen (1988) . "],["scoring-di-strumenti-unidimensionali-con-item-dicotomici.html", "Scoring di strumenti unidimensionali con item dicotomici", " Scoring di strumenti unidimensionali con item dicotomici Per concludere la parte relativa ai test dicotomici, dopo aver affrontato la calibrazione, vediamo di seguito come è possibile effettuare lo scoring di un test usando Expected a Posteriori Score (EAP; Bock &amp; Mislevy, 1982). Gli EAP rappresentano la stima probabilistica a posteriori del tratto latente di ogni rispondente, dopo che sono stati osservati i parametri degli item. Ha numerosi vantaggi, fra i quali: Si basa sui pattern di risposta e non sulla semplice somma dei punteggi agli item; Ha lo stesso scaling della location dellitem; Fornisce anche una stima della precisione del puteggio (SD EAP). Per ottenere gli EAP in mirt dobbiamo usare la funzione fscores(). Tramite largomento full.scores.SE=TRUE possiamo ottenere anche la stima dellerrore associato alla misura e, quindi, della sua precisione. #Calcolo gli EAP scores eap&lt;-fscores(MOD.2PL,method = &#39;EAP&#39;, full.scores.SE = TRUE) colnames(eap)[1]&lt;- &#39;EAP&#39; colnames(eap)[2]&lt;- &#39;SD_EAP&#39; Poiché viene stimato un punteggio per ogni rispondente, possiamo unire le nuove colonne al nostro database usando la funzione cbind(). TEST.DIC.EAP&lt;-cbind(TEST.DIC, eap) TEST.DIC.EAP ## sex country ITEM_DIC_1 ITEM_DIC_2 ITEM_DIC_3 ITEM_DIC_4 ITEM_DIC_5 ## 1 2 1 0 0 0 0 0 ## 2 2 1 0 0 0 0 0 ## 3 2 1 0 0 0 0 0 ## 4 2 1 0 0 0 0 0 ## 5 2 1 0 0 0 0 0 ## 6 1 1 0 0 0 0 0 ## 7 2 1 0 0 0 0 0 ## 8 2 1 0 0 0 0 0 ## 9 1 2 0 0 0 0 0 ## 10 1 2 0 0 0 0 0 ## 11 2 2 0 0 0 0 0 ## 12 1 2 0 0 0 0 0 ## 13 1 2 0 0 0 0 0 ## 14 1 2 0 0 0 0 0 ## 15 1 2 0 0 0 0 0 ## 16 1 2 0 0 0 0 0 ## 17 1 2 0 0 0 0 0 ## 18 1 2 0 0 0 0 0 ## 19 1 2 0 0 0 0 0 ## 20 1 2 0 0 0 0 0 ## 21 NA 2 0 0 0 0 0 ## 22 2 1 1 0 0 0 0 ## 23 2 1 1 0 0 0 0 ## 24 1 2 0 1 0 0 0 ## 25 1 2 0 1 0 0 0 ## 26 2 1 0 0 1 0 0 ## 27 2 2 1 0 1 0 0 ## 28 2 1 0 0 0 1 0 ## 29 1 2 0 0 0 1 0 ## 30 1 1 1 0 0 1 0 ## 31 2 1 1 0 0 1 0 ## 32 1 2 1 0 0 1 0 ## 33 2 1 0 0 0 0 1 ## 34 1 1 0 0 0 0 1 ## 35 2 1 0 0 0 0 1 ## 36 2 1 0 0 0 0 1 ## 37 2 1 0 0 0 0 1 ## 38 2 1 0 0 0 0 1 ## 39 2 1 0 0 0 0 1 ## 40 2 1 0 0 0 0 1 ## 41 2 1 0 0 0 0 1 ## 42 2 1 0 0 0 0 1 ## 43 2 1 0 0 0 0 1 ## 44 2 1 0 0 0 0 1 ## 45 2 1 0 0 0 0 1 ## 46 2 1 0 0 0 0 1 ## 47 2 1 0 0 0 0 1 ## 48 2 1 0 0 0 0 1 ## 49 1 2 0 0 0 0 1 ## 50 2 2 0 0 0 0 1 ## 51 1 2 0 0 0 0 1 ## 52 1 2 0 0 0 0 1 ## 53 1 2 0 0 0 0 1 ## 54 1 2 0 0 0 0 1 ## 55 1 2 0 0 0 0 1 ## 56 2 2 0 0 0 0 1 ## 57 1 2 0 0 0 0 1 ## 58 NA 2 0 0 0 0 1 ## 59 1 2 0 0 0 0 1 ## 60 2 2 0 0 0 0 1 ## 61 1 1 1 0 0 0 1 ## 62 2 1 1 0 0 0 1 ## 63 2 1 1 0 0 0 1 ## 64 1 2 1 0 0 0 1 ## 65 1 2 1 0 0 0 1 ## 66 1 2 0 1 0 0 1 ## 67 2 1 0 0 1 0 1 ## 68 2 1 0 0 1 0 1 ## 69 2 1 0 0 1 0 1 ## 70 2 1 0 0 1 0 1 ## 71 2 1 0 0 1 0 1 ## 72 1 2 0 0 1 0 1 ## 73 1 2 0 0 1 0 1 ## 74 2 1 1 0 1 0 1 ## 75 2 1 1 0 1 0 1 ## 76 1 1 0 0 0 1 1 ## 77 1 1 0 0 0 1 1 ## 78 1 1 0 0 0 1 1 ## 79 1 1 0 0 0 1 1 ## 80 2 1 0 0 0 1 1 ## 81 2 1 0 0 0 1 1 ## 82 1 2 0 0 0 1 1 ## 83 2 2 0 0 0 1 1 ## 84 1 2 0 0 0 1 1 ## 85 1 2 0 0 0 1 1 ## 86 1 2 0 0 0 1 1 ## 87 1 1 0 0 1 1 1 ## 88 1 1 0 0 1 1 1 ## 89 2 1 0 0 1 1 1 ## 90 2 1 1 0 1 1 1 ## ITEM_DIC_6 ITEM_DIC_7 EAP SD_EAP ## 1 0 0 -1.46448628 0.6573869 ## 2 0 0 -1.46448628 0.6573869 ## 3 0 0 -1.46448628 0.6573869 ## 4 0 0 -1.46448628 0.6573869 ## 5 0 0 -1.46448628 0.6573869 ## 6 0 0 -1.46448628 0.6573869 ## 7 0 0 -1.46448628 0.6573869 ## 8 0 0 -1.46448628 0.6573869 ## 9 0 0 -1.46448628 0.6573869 ## 10 0 0 -1.46448628 0.6573869 ## 11 0 0 -1.46448628 0.6573869 ## 12 0 0 -1.46448628 0.6573869 ## 13 0 0 -1.46448628 0.6573869 ## 14 0 0 -1.46448628 0.6573869 ## 15 0 0 -1.46448628 0.6573869 ## 16 0 0 -1.46448628 0.6573869 ## 17 0 0 -1.46448628 0.6573869 ## 18 0 0 -1.46448628 0.6573869 ## 19 0 0 -1.46448628 0.6573869 ## 20 0 0 -1.46448628 0.6573869 ## 21 0 0 -1.46448628 0.6573869 ## 22 0 0 -0.80440187 0.5504950 ## 23 0 0 -0.80440187 0.5504950 ## 24 0 0 -0.83951106 0.5560183 ## 25 0 0 -0.83951106 0.5560183 ## 26 0 0 -0.86594932 0.5602050 ## 27 0 0 -0.36923624 0.4885994 ## 28 0 0 -0.49273305 0.5044352 ## 29 0 0 -0.49273305 0.5044352 ## 30 0 0 -0.07300478 0.4604422 ## 31 0 0 -0.07300478 0.4604422 ## 32 0 0 -0.07300478 0.4604422 ## 33 0 0 -0.82034309 0.5529974 ## 34 0 0 -0.82034309 0.5529974 ## 35 0 0 -0.82034309 0.5529974 ## 36 0 0 -0.82034309 0.5529974 ## 37 0 0 -0.82034309 0.5529974 ## 38 0 0 -0.82034309 0.5529974 ## 39 0 0 -0.82034309 0.5529974 ## 40 0 0 -0.82034309 0.5529974 ## 41 0 0 -0.82034309 0.5529974 ## 42 0 0 -0.82034309 0.5529974 ## 43 0 0 -0.82034309 0.5529974 ## 44 0 0 -0.82034309 0.5529974 ## 45 0 0 -0.82034309 0.5529974 ## 46 0 0 -0.82034309 0.5529974 ## 47 0 0 -0.82034309 0.5529974 ## 48 0 0 -0.82034309 0.5529974 ## 49 0 0 -0.82034309 0.5529974 ## 50 0 0 -0.82034309 0.5529974 ## 51 0 0 -0.82034309 0.5529974 ## 52 0 0 -0.82034309 0.5529974 ## 53 0 0 -0.82034309 0.5529974 ## 54 0 0 -0.82034309 0.5529974 ## 55 0 0 -0.82034309 0.5529974 ## 56 0 0 -0.82034309 0.5529974 ## 57 0 0 -0.82034309 0.5529974 ## 58 0 0 -0.82034309 0.5529974 ## 59 0 0 -0.82034309 0.5529974 ## 60 0 0 -0.82034309 0.5529974 ## 61 0 0 -0.33438813 0.4844955 ## 62 0 0 -0.33438813 0.4844955 ## 63 0 0 -0.33438813 0.4844955 ## 64 0 0 -0.33438813 0.4844955 ## 65 0 0 -0.33438813 0.4844955 ## 66 0 0 -0.36148913 0.4876718 ## 67 0 0 -0.38177624 0.4901188 ## 68 0 0 -0.38177624 0.4901188 ## 69 0 0 -0.38177624 0.4901188 ## 70 0 0 -0.38177624 0.4901188 ## 71 0 0 -0.38177624 0.4901188 ## 72 0 0 -0.38177624 0.4901188 ## 73 0 0 -0.38177624 0.4901188 ## 74 0 0 0.02104946 0.4552613 ## 75 0 0 0.02104946 0.4552613 ## 76 0 0 -0.08412452 0.4611871 ## 77 0 0 -0.08412452 0.4611871 ## 78 0 0 -0.08412452 0.4611871 ## 79 0 0 -0.08412452 0.4611871 ## 80 0 0 -0.08412452 0.4611871 ## 81 0 0 -0.08412452 0.4611871 ## 82 0 0 -0.08412452 0.4611871 ## 83 0 0 -0.08412452 0.4611871 ## 84 0 0 -0.08412452 0.4611871 ## 85 0 0 -0.08412452 0.4611871 ## 86 0 0 -0.08412452 0.4611871 ## 87 0 0 0.25111731 0.4514195 ## 88 0 0 0.25111731 0.4514195 ## 89 0 0 0.25111731 0.4514195 ## 90 0 0 0.63506533 0.4706872 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 328 rows ] "],["calibrazione-di-strumenti-unidimensionali-con-item-politomici.html", "Calibrazione di strumenti unidimensionali con item politomici", " Calibrazione di strumenti unidimensionali con item politomici In questa sezione tratteremo gli strumenti unidimensionali con item politomici, ovvero quegli strumenti dove tutti gli item misurano lo stesso tratto latente (theta) e le risposte vengono raccolte tramite una scala Likert (ovvero, categorie di risposta ordinate). Il modello maggiormente utilizzato per la calibrazione di strumenti politomici con risposte ordinate è il graded model (Samejima, 1968). In questo modello, ogni item ha la propria capacità discriminativa (indicata sempre con a1). Inoltre, ogni item ha un numero di parametri di location uguali al numero di punti della scala Likert meno 1. Ad esempio, un item raccolto sul scala Likert a 5 punti, avrà 4 parametri di location, denominati \\(b_1, b_2, b_3\\) e \\(b_4\\). Questi parametri sono denominati soglie e rappresentano il punto esatto lungo il continuum di theta dove la probabilità di dare la risposta che precede la soglia o la risposta che segue la soglia si equivalgono. Ad esempio la soglia \\(b_4\\) è uguale a 1.59, ciò significa che una persona con livello di theta di 1.59 ha la stessa probabilità di dare le risposte 4 e 5 alla scala Likert. Una persona con theta di 1.58 avrà una maggior probabilità di dare la risposta 4, mentre una persona con theta di 1.60 avrà invece una probabilità maggiore di dare la risposta 5. Caricare i dati Per mostrare la calibrazione di uno strumento tramite il graded model, usaremo come esempio un altro database di prova (denominato TEST.POLY) gentilmente messo a disposizione dal Laboratorio di Psicometria dellUniversità di Firenze. Il database contiene le risposte di 790 persone, tramite sei item su scala Likert a 5 punti (1=Molto raramente; 5=Molto spesso). I dati sono scaricabili da qui. Per caricare i dati, come già visto, carichiamo la libreria haven (i dati sono in .sav) e importiamo il database TEST.POLY.sav tramite la funzione read_sav() del paccheto haven. library(haven) TEST.POLY&lt;-read_sav(&quot;C:/Users/.../TEST.POLY.sav&quot;) Poiché nel database comapre anche la variabile relativa al sesso dei partecipanti, procediamo a selezionare solo gli item per la calibrazione. #Seleziono solo gli item della scala TEST.POLY TEST.POLY.item &lt;-TEST.POLY[,2:7] Calibrazione modello graded In primo luogo, bisogna richiamare le librerie (solo se è stato chiuso RStudio dallultima sessione). library(mirt) library(tidyverse) Come già visto per la calibrazione di modelli dicotomici, il primo passaggio consiste nel definire la struttura fattoriale tramite la funzione mirt.model(). Dato che il modello è unidimensionale, tutti gli item satureranno sul medesimo fattore (F1=1-6). #Struttura fattoriale TEST.POLY modello graded fct.str.graded &lt;- mirt.model(&#39;F1 = 1-6&#39;) Per calibrare il modello, utilizziamo sempre la funzione mirt(). Allinterno dellargomento model inseriremo la struttura fattoriale appena creata (model=fct.str.graded). Largomento itemtype va invece impostato sul modello graded. #Calibrazione modello graded MOD.graded &lt;- mirt(data=TEST.POLY.item, model=fct.str.graded, itemtype = &quot;graded&quot;) ## Iteration: 1, Log-Lik: -4645.078, Max-Change: 1.24068 Iteration: 2, Log-Lik: -4533.408, Max-Change: 0.84912 Iteration: 3, Log-Lik: -4498.926, Max-Change: 0.61870 Iteration: 4, Log-Lik: -4487.027, Max-Change: 0.25941 Iteration: 5, Log-Lik: -4482.706, Max-Change: 0.13665 Iteration: 6, Log-Lik: -4481.054, Max-Change: 0.08618 Iteration: 7, Log-Lik: -4480.052, Max-Change: 0.05800 Iteration: 8, Log-Lik: -4479.866, Max-Change: 0.03152 Iteration: 9, Log-Lik: -4479.771, Max-Change: 0.02317 Iteration: 10, Log-Lik: -4479.689, Max-Change: 0.01067 Iteration: 11, Log-Lik: -4479.669, Max-Change: 0.00692 Iteration: 12, Log-Lik: -4479.656, Max-Change: 0.00647 Iteration: 13, Log-Lik: -4479.643, Max-Change: 0.00292 Iteration: 14, Log-Lik: -4479.638, Max-Change: 0.00297 Iteration: 15, Log-Lik: -4479.635, Max-Change: 0.00231 Iteration: 16, Log-Lik: -4479.630, Max-Change: 0.00401 Iteration: 17, Log-Lik: -4479.629, Max-Change: 0.00079 Iteration: 18, Log-Lik: -4479.629, Max-Change: 0.00044 Iteration: 19, Log-Lik: -4479.629, Max-Change: 0.00045 Iteration: 20, Log-Lik: -4479.628, Max-Change: 0.00049 Iteration: 21, Log-Lik: -4479.628, Max-Change: 0.00054 Iteration: 22, Log-Lik: -4479.628, Max-Change: 0.00033 Iteration: 23, Log-Lik: -4479.628, Max-Change: 0.00036 Iteration: 24, Log-Lik: -4479.628, Max-Change: 0.00040 Iteration: 25, Log-Lik: -4479.628, Max-Change: 0.00026 Iteration: 26, Log-Lik: -4479.628, Max-Change: 0.00028 Iteration: 27, Log-Lik: -4479.628, Max-Change: 0.00032 Iteration: 28, Log-Lik: -4479.628, Max-Change: 0.00021 Iteration: 29, Log-Lik: -4479.628, Max-Change: 0.00024 Iteration: 30, Log-Lik: -4479.628, Max-Change: 0.00027 Iteration: 31, Log-Lik: -4479.628, Max-Change: 0.00019 Iteration: 32, Log-Lik: -4479.628, Max-Change: 0.00021 Iteration: 33, Log-Lik: -4479.628, Max-Change: 0.00024 Iteration: 34, Log-Lik: -4479.628, Max-Change: 0.00016 Iteration: 35, Log-Lik: -4479.628, Max-Change: 0.00019 Iteration: 36, Log-Lik: -4479.628, Max-Change: 0.00021 Iteration: 37, Log-Lik: -4479.628, Max-Change: 0.00015 Iteration: 38, Log-Lik: -4479.628, Max-Change: 0.00017 Iteration: 39, Log-Lik: -4479.628, Max-Change: 0.00019 Iteration: 40, Log-Lik: -4479.628, Max-Change: 0.00014 Iteration: 41, Log-Lik: -4479.628, Max-Change: 0.00016 Iteration: 42, Log-Lik: -4479.628, Max-Change: 0.00018 Iteration: 43, Log-Lik: -4479.628, Max-Change: 0.00013 Iteration: 44, Log-Lik: -4479.628, Max-Change: 0.00014 Iteration: 45, Log-Lik: -4479.628, Max-Change: 0.00016 Iteration: 46, Log-Lik: -4479.628, Max-Change: 0.00011 Iteration: 47, Log-Lik: -4479.628, Max-Change: 0.00013 Iteration: 48, Log-Lik: -4479.628, Max-Change: 0.00015 Iteration: 49, Log-Lik: -4479.628, Max-Change: 0.00011 Iteration: 50, Log-Lik: -4479.628, Max-Change: 0.00012 Iteration: 51, Log-Lik: -4479.628, Max-Change: 0.00014 Iteration: 52, Log-Lik: -4479.628, Max-Change: 0.00011 Iteration: 53, Log-Lik: -4479.628, Max-Change: 0.00011 Iteration: 54, Log-Lik: -4479.628, Max-Change: 0.00013 Iteration: 55, Log-Lik: -4479.628, Max-Change: 0.00010 Iteration: 56, Log-Lik: -4479.628, Max-Change: 0.00010 Iteration: 57, Log-Lik: -4479.628, Max-Change: 0.00012 Iteration: 58, Log-Lik: -4479.628, Max-Change: 0.00010 Verifica delle assunzioni Verifichiamo ora lassunzione di unidimensionalità tramite la statistica di Local Dependence (LD, Chen &amp; Thissen, 1997) visualizzabile tramite la funzione residuals(). Procediamo poi osservando anche le saturazioni degli item sul fattore con la funzione summary(). #Assunzioni graded residuals(MOD.graded,type=&#39;LD&#39;,df.p=TRUE) #LD per il modello greaded ## Degrees of freedom (lower triangle) and p-values: ## ## ITEM_POLY_1 ITEM_POLY_2 ITEM_POLY_3 ITEM_POLY_4 ITEM_POLY_5 ## ITEM_POLY_1 NA 0.001 0.008 0.022 0.045 ## ITEM_POLY_2 16 NA 0.001 0.000 0.002 ## ITEM_POLY_3 16 16.000 NA 0.009 0.285 ## ITEM_POLY_4 16 16.000 16.000 NA 0.108 ## ITEM_POLY_5 16 16.000 16.000 16.000 NA ## ITEM_POLY_6 16 16.000 16.000 16.000 16.000 ## ITEM_POLY_6 ## ITEM_POLY_1 0.478 ## ITEM_POLY_2 0.000 ## ITEM_POLY_3 0.038 ## ITEM_POLY_4 0.001 ## ITEM_POLY_5 0.035 ## ITEM_POLY_6 NA ## ## LD matrix (lower triangle) and standardized values. ## ## Upper triangle summary: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.118 -0.106 -0.092 -0.023 0.089 0.113 ## ## ITEM_POLY_1 ITEM_POLY_2 ITEM_POLY_3 ITEM_POLY_4 ITEM_POLY_5 ## ITEM_POLY_1 NA 0.113 -0.102 -0.096 -0.092 ## ITEM_POLY_2 40.212 NA -0.112 -0.118 -0.109 ## ITEM_POLY_3 32.761 39.919 NA 0.101 -0.077 ## ITEM_POLY_4 29.242 43.927 32.173 NA 0.086 ## ITEM_POLY_5 26.708 37.794 18.698 23.223 NA ## ITEM_POLY_6 15.640 42.481 27.294 39.625 27.577 ## ITEM_POLY_6 ## ITEM_POLY_1 0.070 ## ITEM_POLY_2 -0.116 ## ITEM_POLY_3 0.093 ## ITEM_POLY_4 0.112 ## ITEM_POLY_5 -0.093 ## ITEM_POLY_6 NA summary(MOD.graded) #Saturazioni 1PL ## F1 h2 ## ITEM_POLY_1 0.709 0.503 ## ITEM_POLY_2 0.857 0.734 ## ITEM_POLY_3 0.621 0.386 ## ITEM_POLY_4 0.706 0.499 ## ITEM_POLY_5 0.802 0.643 ## ITEM_POLY_6 0.630 0.397 ## ## SS loadings: 3.161 ## Proportion Var: 0.527 ## ## Factor correlations: ## ## F1 ## F1 1 Fit del modello e degli item Verificate le assunzioni, è possibile procedere con il fit, prima del modello e poi degli item. Nel caso del fit del modello, utilizzeremo unaltra variante della statistica \\(M_2\\) (Maydeu -Olivares, &amp; Joe, 2006; Maydeu-Olivares, &amp; Joe, 2014), ovvero la stastistica C2 (Cai, &amp; Monroe, 2014). A differenza della statistica \\(M_2\\), la statistica C2 può essere utilizzata anche con pochi item con tante categorie di risposta. Per ottenere la statistica C2 useremo sempre la funzione M2(), inserendo però come argomento type='C2'. M2(MOD.graded,type = &#39;C2&#39;) #Fit Globale graded ## M2 df p RMSEA RMSEA_5 RMSEA_95 ## stats 48.58374 9 1.986294e-07 0.07466183 0.0548381 0.09583464 ## SRMSR TLI CFI ## stats 0.05477425 0.9579285 0.9747571 Proseguiamo poi con il fit fi ogni item tramite la statistica \\(S-X^2\\) (Orlando &amp; Thissen, 2000), utilizzando come soglia p&lt; .01. itemfit(MOD.graded, fit_stats = &quot;S_X2&quot;, na.rm = T) #fit degli item nel graded ## Data does not contain missing values. Continuing normally ## Sample size after row-wise response data removal: 790 ## item S_X2 df.S_X2 RMSEA.S_X2 p.S_X2 ## 1 ITEM_POLY_1 52.244 38 0.022 0.062 ## 2 ITEM_POLY_2 33.080 23 0.024 0.080 ## 3 ITEM_POLY_3 41.650 40 0.007 0.399 ## 4 ITEM_POLY_4 55.224 36 0.026 0.021 ## 5 ITEM_POLY_5 19.474 28 0.000 0.883 ## 6 ITEM_POLY_6 34.518 33 0.008 0.395 Parametri degli item e Response Characteristic Curves (RCCs) Tramite la funzione coef() richiediamo i parametri del modello. COEF.graded&lt;-coef(MOD.graded, IRTpars=TRUE, simplify=TRUE) COEF.graded ## $items ## a b1 b2 b3 b4 ## ITEM_POLY_1 1.713 0.172 1.191 2.090 2.705 ## ITEM_POLY_2 2.825 0.201 1.071 1.868 2.625 ## ITEM_POLY_3 1.348 0.533 1.455 2.424 3.373 ## ITEM_POLY_4 1.697 0.331 1.242 2.057 2.926 ## ITEM_POLY_5 2.283 0.845 1.644 2.283 3.012 ## ITEM_POLY_6 1.381 0.706 1.798 2.811 3.616 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Proseguiamo poi con lispezione delle RCCs tramite la funzione itemplot(). Poiché è stato impostato il modello graded, impostando largomento type=trace, otterremo le RCCs. Tramite largomento item è possibile selezionare le RCCs dellitem che si desidera visualizzare. Nellesempio sottostante, litem scelto è il primo (item=1). itemplot(MOD.graded,type = &#39;trace&#39;, item =1) #RCC del primo item Se si desidera ottenere le RCCs di tutti gli item del test con un solo comando, si può utilizzare un ciclo for(). # Stampa di tutte le RCCs di tutti gli item del test for(i in 1:extract.mirt(MOD.graded, &quot;nitems&quot;)) {plot(MOD.graded, type = &#39;trace&#39;,which.items = i, facet_items=TRUE, theta_lim = c(-3, 3))} %&gt;% print() Item Information Functions (IIFs) e Test Information Function (TIF) Linformazione apportata da ogni singolo item può essere visualizzata sempre con il comando itemplot(), impostando però largomento type ='info' . itemplot(MOD.graded,type =&#39;info&#39;, item =1) #IIF del primo item Se si desidera ottenere tutte le IIF degli item del test con un solo comando, si può utilizzare un ciclo for(): #IIF per il modello graded for (i in 1:extract.mirt(MOD.graded, &quot;nitems&quot;)) {plot(MOD.graded, type = &#39;infotrace&#39;, which.items = i,facet_items=TRUE, theta_lim = c(-3, 3))} %&gt;% print() Infine, tramite la funzione plot() è possibile ottenere la TIF del test e lerrore di misura. #TIF modello graded plot(MOD.graded, type = &#39;infoSE&#39;, which.items = 1:extract.mirt(MOD.graded, &quot;nitems&quot;), theta_lim = c(-3, 3)) "],["differential-item-functioning-per-item-politomici.html", "Differential Item Functioning per item politomici", " Differential Item Functioning per item politomici La procedura per lo studio dellinvarianza a livello di item calibrati tramite il modello graded è la medesima illustrata per il modello 2PL. Di seguito verrà illustrata linvarianza di genere della scala TEST.POLY, utilizzando la varibile SESSO (1=maschio, 2=femmina). Per prima cosa selezioniamo la variabile gruppo. GRUPPO&lt;-as.factor(TEST.POLY$SESSO) #var. gruppo Selezioniamo poi gli item sui quali condurre linvarianza. item.DIF.graded&lt;-TEST.POLY[,2:7] #item per DIF Definiamo poi la struttura fattoriale, come già fatto in precedenza. fct.str.DIF &lt;- mirt.model(&#39;F1 = 1-6&#39;) Infine, creiamo un oggetto contenente il tipo di modello, per non doverlo inserire in ogni passaggio. tipo.mod&lt;-&#39;graded&#39; Stima dei parametri nei due gruppi Procediamo alla stima dei parametri degli item nel gruppo di maschi inserendo letichetta 1 allinterno della voce GRUPPO (GRUPPO==1). mod.group1&lt;-filter(item.DIF.graded, GRUPPO==&#39;1&#39;)%&gt;% #Inserire il gruppo mirt(model=fct.str.DIF, itemtype = tipo.mod) ## Iteration: 1, Log-Lik: -2258.829, Max-Change: 1.87997 Iteration: 2, Log-Lik: -2204.298, Max-Change: 0.71480 Iteration: 3, Log-Lik: -2190.205, Max-Change: 0.25293 Iteration: 4, Log-Lik: -2185.405, Max-Change: 0.17363 Iteration: 5, Log-Lik: -2183.512, Max-Change: 0.13165 Iteration: 6, Log-Lik: -2182.675, Max-Change: 0.09156 Iteration: 7, Log-Lik: -2182.133, Max-Change: 0.06461 Iteration: 8, Log-Lik: -2182.007, Max-Change: 0.03479 Iteration: 9, Log-Lik: -2181.939, Max-Change: 0.02677 Iteration: 10, Log-Lik: -2181.867, Max-Change: 0.01570 Iteration: 11, Log-Lik: -2181.852, Max-Change: 0.00664 Iteration: 12, Log-Lik: -2181.844, Max-Change: 0.00561 Iteration: 13, Log-Lik: -2181.837, Max-Change: 0.00298 Iteration: 14, Log-Lik: -2181.834, Max-Change: 0.00202 Iteration: 15, Log-Lik: -2181.833, Max-Change: 0.00175 Iteration: 16, Log-Lik: -2181.831, Max-Change: 0.00090 Iteration: 17, Log-Lik: -2181.831, Max-Change: 0.00106 Iteration: 18, Log-Lik: -2181.831, Max-Change: 0.00069 Iteration: 19, Log-Lik: -2181.830, Max-Change: 0.00067 Iteration: 20, Log-Lik: -2181.830, Max-Change: 0.00058 Iteration: 21, Log-Lik: -2181.830, Max-Change: 0.00051 Iteration: 22, Log-Lik: -2181.830, Max-Change: 0.00011 Iteration: 23, Log-Lik: -2181.830, Max-Change: 0.00033 Iteration: 24, Log-Lik: -2181.830, Max-Change: 0.00036 Iteration: 25, Log-Lik: -2181.830, Max-Change: 0.00013 Iteration: 26, Log-Lik: -2181.830, Max-Change: 0.00028 Iteration: 27, Log-Lik: -2181.830, Max-Change: 0.00010 coef(mod.group1, simplify=TRUE, IRTpars=T) #stampa dei parametri ## $items ## a b1 b2 b3 b4 ## ITEM_POLY_1 1.650 0.164 1.240 2.184 2.874 ## ITEM_POLY_2 2.636 0.181 1.107 2.087 3.325 ## ITEM_POLY_3 1.302 0.670 1.736 2.668 3.451 ## ITEM_POLY_4 1.481 0.343 1.427 2.316 3.348 ## ITEM_POLY_5 2.404 0.922 1.686 2.395 3.482 ## ITEM_POLY_6 1.651 0.576 1.589 2.398 3.241 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Stimiamo poi i parametri nel gruppo delle femmine (GRUPPO==2). mod.group2&lt;-filter(item.DIF.graded, GRUPPO==&#39;2&#39;)%&gt;% #Inserire il gruppo mirt(model=fct.str.DIF, itemtype = tipo.mod) ## Iteration: 1, Log-Lik: -2371.369, Max-Change: 1.15938 Iteration: 2, Log-Lik: -2308.183, Max-Change: 0.68798 Iteration: 3, Log-Lik: -2290.871, Max-Change: 0.46868 Iteration: 4, Log-Lik: -2284.622, Max-Change: 0.27333 Iteration: 5, Log-Lik: -2282.229, Max-Change: 0.17879 Iteration: 6, Log-Lik: -2281.174, Max-Change: 0.09382 Iteration: 7, Log-Lik: -2280.624, Max-Change: 0.06485 Iteration: 8, Log-Lik: -2280.391, Max-Change: 0.04768 Iteration: 9, Log-Lik: -2280.259, Max-Change: 0.03492 Iteration: 10, Log-Lik: -2280.109, Max-Change: 0.01516 Iteration: 11, Log-Lik: -2280.086, Max-Change: 0.01008 Iteration: 12, Log-Lik: -2280.070, Max-Change: 0.00740 Iteration: 13, Log-Lik: -2280.058, Max-Change: 0.00863 Iteration: 14, Log-Lik: -2280.051, Max-Change: 0.00441 Iteration: 15, Log-Lik: -2280.046, Max-Change: 0.00350 Iteration: 16, Log-Lik: -2280.037, Max-Change: 0.00182 Iteration: 17, Log-Lik: -2280.036, Max-Change: 0.00137 Iteration: 18, Log-Lik: -2280.036, Max-Change: 0.00169 Iteration: 19, Log-Lik: -2280.035, Max-Change: 0.00107 Iteration: 20, Log-Lik: -2280.035, Max-Change: 0.00082 Iteration: 21, Log-Lik: -2280.035, Max-Change: 0.00065 Iteration: 22, Log-Lik: -2280.034, Max-Change: 0.00048 Iteration: 23, Log-Lik: -2280.034, Max-Change: 0.00032 Iteration: 24, Log-Lik: -2280.034, Max-Change: 0.00042 Iteration: 25, Log-Lik: -2280.034, Max-Change: 0.00030 Iteration: 26, Log-Lik: -2280.034, Max-Change: 0.00038 Iteration: 27, Log-Lik: -2280.034, Max-Change: 0.00029 Iteration: 28, Log-Lik: -2280.034, Max-Change: 0.00017 Iteration: 29, Log-Lik: -2280.034, Max-Change: 0.00030 Iteration: 30, Log-Lik: -2280.034, Max-Change: 0.00016 Iteration: 31, Log-Lik: -2280.034, Max-Change: 0.00011 Iteration: 32, Log-Lik: -2280.034, Max-Change: 0.00029 Iteration: 33, Log-Lik: -2280.034, Max-Change: 0.00010 Iteration: 34, Log-Lik: -2280.034, Max-Change: 0.00037 Iteration: 35, Log-Lik: -2280.034, Max-Change: 0.00030 Iteration: 36, Log-Lik: -2280.034, Max-Change: 0.00035 Iteration: 37, Log-Lik: -2280.034, Max-Change: 0.00022 Iteration: 38, Log-Lik: -2280.034, Max-Change: 0.00026 Iteration: 39, Log-Lik: -2280.034, Max-Change: 0.00021 Iteration: 40, Log-Lik: -2280.034, Max-Change: 0.00011 Iteration: 41, Log-Lik: -2280.034, Max-Change: 0.00024 Iteration: 42, Log-Lik: -2280.034, Max-Change: 0.00011 Iteration: 43, Log-Lik: -2280.034, Max-Change: 0.00007 coef(mod.group2, simplify=TRUE, IRTpars=T) #stampa dei parametri ## $items ## a b1 b2 b3 b4 ## ITEM_POLY_1 1.737 0.181 1.160 2.033 2.594 ## ITEM_POLY_2 2.966 0.221 1.049 1.717 2.348 ## ITEM_POLY_3 1.428 0.401 1.199 2.184 3.246 ## ITEM_POLY_4 1.948 0.319 1.089 1.853 2.608 ## ITEM_POLY_5 2.177 0.771 1.604 2.200 2.812 ## ITEM_POLY_6 1.189 0.862 2.036 3.338 4.030 ## ## $means ## F1 ## 0 ## ## $cov ## F1 ## F1 1 Primo step della procedura di purificazione Procediamo poi con il primo step della procedura di purificazione, stimando un modello di partenza tramite la funzione multiplegroup(), dove nell argomento invariance =c() provvederemo a: vincolare i parametri degli item essere uguali nei due gruppi (colnames(item.DIF.graded)); Fissare le medie a 0 nel gruppo di riferimento e a lasciarle libere nel gruppo focale ('free_means'); Fissare le varianze a 1 nel gruppo di riferimento e a lasciarle libere nel gruppo focale ('free_var' ); #Primo step della procedura di purificazione. #Stima del modello di partenza mod.dif.1&lt;-multipleGroup(item.DIF.graded,model=fct.str.DIF, itemtype =tipo.mod,group =GRUPPO,SE=TRUE, invariance = c(colnames(item.DIF.graded), &#39;free_means&#39;, &#39;free_var&#39;)) ## Iteration: 1, Log-Lik: -4645.078, Max-Change: 1.24819 Iteration: 2, Log-Lik: -4513.557, Max-Change: 0.70263 Iteration: 3, Log-Lik: -4489.304, Max-Change: 0.37508 Iteration: 4, Log-Lik: -4483.992, Max-Change: 0.23986 Iteration: 5, Log-Lik: -4482.128, Max-Change: 0.14803 Iteration: 6, Log-Lik: -4481.215, Max-Change: 0.11593 Iteration: 7, Log-Lik: -4480.128, Max-Change: 0.06541 Iteration: 8, Log-Lik: -4479.787, Max-Change: 0.04103 Iteration: 9, Log-Lik: -4479.561, Max-Change: 0.03151 Iteration: 10, Log-Lik: -4479.277, Max-Change: 0.03881 Iteration: 11, Log-Lik: -4479.129, Max-Change: 0.02506 Iteration: 12, Log-Lik: -4479.026, Max-Change: 0.01979 Iteration: 13, Log-Lik: -4478.876, Max-Change: 0.04245 Iteration: 14, Log-Lik: -4478.734, Max-Change: 0.01965 Iteration: 15, Log-Lik: -4478.691, Max-Change: 0.01274 Iteration: 16, Log-Lik: -4478.660, Max-Change: 0.01060 Iteration: 17, Log-Lik: -4478.639, Max-Change: 0.00832 Iteration: 18, Log-Lik: -4478.622, Max-Change: 0.00712 Iteration: 19, Log-Lik: -4478.597, Max-Change: 0.01722 Iteration: 20, Log-Lik: -4478.570, Max-Change: 0.00782 Iteration: 21, Log-Lik: -4478.563, Max-Change: 0.00498 Iteration: 22, Log-Lik: -4478.558, Max-Change: 0.00395 Iteration: 23, Log-Lik: -4478.554, Max-Change: 0.00318 Iteration: 24, Log-Lik: -4478.552, Max-Change: 0.00274 Iteration: 25, Log-Lik: -4478.547, Max-Change: 0.00677 Iteration: 26, Log-Lik: -4478.543, Max-Change: 0.00307 Iteration: 27, Log-Lik: -4478.542, Max-Change: 0.00195 Iteration: 28, Log-Lik: -4478.541, Max-Change: 0.00156 Iteration: 29, Log-Lik: -4478.540, Max-Change: 0.00126 Iteration: 30, Log-Lik: -4478.540, Max-Change: 0.00108 Iteration: 31, Log-Lik: -4478.539, Max-Change: 0.00272 Iteration: 32, Log-Lik: -4478.539, Max-Change: 0.00122 Iteration: 33, Log-Lik: -4478.538, Max-Change: 0.00079 Iteration: 34, Log-Lik: -4478.538, Max-Change: 0.00064 Iteration: 35, Log-Lik: -4478.538, Max-Change: 0.00051 Iteration: 36, Log-Lik: -4478.538, Max-Change: 0.00044 Iteration: 37, Log-Lik: -4478.538, Max-Change: 0.00109 Iteration: 38, Log-Lik: -4478.538, Max-Change: 0.00049 Iteration: 39, Log-Lik: -4478.538, Max-Change: 0.00031 Iteration: 40, Log-Lik: -4478.538, Max-Change: 0.00028 Iteration: 41, Log-Lik: -4478.538, Max-Change: 0.00021 Iteration: 42, Log-Lik: -4478.538, Max-Change: 0.00018 Iteration: 43, Log-Lik: -4478.538, Max-Change: 0.00044 Iteration: 44, Log-Lik: -4478.538, Max-Change: 0.00019 Iteration: 45, Log-Lik: -4478.538, Max-Change: 0.00013 Iteration: 46, Log-Lik: -4478.538, Max-Change: 0.00012 Iteration: 47, Log-Lik: -4478.538, Max-Change: 0.00008 ## ## Calculating information matrix... A partire da questo modello, procediamo a stimare il DIF al primo step di interazione tramite la funzione DIF(). Impostando la voce scheme='drop', procediamo rimuovendo i vincoli degli item uno ad uno per essere confrontati tramite il Chi-Quadro nei due gruppi. Primamariamente, verifichiamo la possibile presenza di DIF nei parametri a (which.par = 'a1') #DIF in a al primo step di purificazione DIF(mod.dif.1,which.par = &#39;a1&#39;, simplify = TRUE, scheme = &#39;drop&#39;) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_POLY_1 TRUE 1.750 3.246 3.545 6.422 0.25 1 0.617 ## ITEM_POLY_2 TRUE 1.837 3.334 3.633 6.509 0.163 1 0.687 ## ITEM_POLY_3 TRUE 0.664 2.161 2.460 5.336 1.336 1 0.248 ## ITEM_POLY_4 TRUE 0.467 1.963 2.263 5.139 1.533 1 0.216 ## ITEM_POLY_5 TRUE 1.952 3.449 3.748 6.624 0.048 1 0.827 ## ITEM_POLY_6 TRUE -7.632 -6.135 -5.836 -2.960 9.632 1 0.002 Per quanto riguarda la capacità discriminativa, litem 6 mostrava DIF al primo step di purificazione (\\(X^2\\)(1)=9.63 , p &lt; .01). Proseguiamo poi con la stima del DIF relativo alle soglie. Come per il modello 2PL anche in questo caso va utilizzato il parametro d. Inoltre, inserendo nella funzione which.par =c('d1', 'd2','d3','d4') andiamo a analizzare il DIF nelle soglie congiuntamente. #DIF in a al primo step di purificazione DIF(mod.dif.1,which.par =c(&#39;d1&#39;, &#39;d2&#39;,&#39;d3&#39;,&#39;d4&#39;), simplify = TRUE, scheme = &#39;drop&#39;) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_POLY_1 TRUE 7.579 13.565 14.763 26.267 0.421 4 0.981 ## ITEM_POLY_2 TRUE 1.404 7.390 8.587 20.092 6.596 4 0.159 ## ITEM_POLY_3 TRUE -0.431 5.555 6.753 18.257 8.431 4 0.077 ## ITEM_POLY_4 TRUE 6.801 12.787 13.984 25.489 1.199 4 0.878 ## ITEM_POLY_5 TRUE 4.346 10.332 11.529 23.034 3.654 4 0.455 ## ITEM_POLY_6 TRUE 2.096 8.082 9.279 20.784 5.904 4 0.206 Per quanto riguarda le soglie, nessun item mostrava DIF. Secondo step della procedura di purificazione Procediamo quindi con il secondo step della procedura di purificazione per confermare la possibile presenza di DIF nella capacità discriminativa dellitem 6. Innanzitutto, definiamo gli item ancora. #Definisco gli item ancora itemnames &lt;- colnames(item.DIF.graded) item.ancora&lt;- itemnames[c(1,2,3,4,5)] #Inserire gli item ancora print(item.ancora) ## [1] &quot;ITEM_POLY_1&quot; &quot;ITEM_POLY_2&quot; &quot;ITEM_POLY_3&quot; &quot;ITEM_POLY_4&quot; ## [5] &quot;ITEM_POLY_5&quot; Proseguiamo poi creando un oggetto che contenga litem candidato, ovvero il sesto. #Definisco gli item candidati item.candidati&lt;- c(6) #Inserire gli item candidati print(item.candidati) ## [1] 6 Procediamo poi a creare un nuovo modello tramite la funzione multiplegroup() con i seguenti vincoli allinterno dellargomento invariance=c(): i parametri degli item ancora fissati ad essere uguali nei due gruppi; le medie e le varianze fissate a 0 e 1 nel gruppo focale e libere di essere stimate nel gruppo di riferimento. #Secondo step della procedura di purificazione. #Stima del modello mod.dif.2&lt;-multipleGroup(item.DIF.graded,model=fct.str.DIF, itemtype =tipo.mod,group =GRUPPO,SE=TRUE, invariance = c(item.ancora, &#39;free_means&#39;, &#39;free_var&#39;)) ## Iteration: 1, Log-Lik: -4645.078, Max-Change: 1.25701 Iteration: 2, Log-Lik: -4508.369, Max-Change: 0.70537 Iteration: 3, Log-Lik: -4481.891, Max-Change: 0.39169 Iteration: 4, Log-Lik: -4476.329, Max-Change: 0.23777 Iteration: 5, Log-Lik: -4474.665, Max-Change: 0.14305 Iteration: 6, Log-Lik: -4473.974, Max-Change: 0.11154 Iteration: 7, Log-Lik: -4473.249, Max-Change: 0.05102 Iteration: 8, Log-Lik: -4473.034, Max-Change: 0.03419 Iteration: 9, Log-Lik: -4472.881, Max-Change: 0.02755 Iteration: 10, Log-Lik: -4472.658, Max-Change: 0.04140 Iteration: 11, Log-Lik: -4472.538, Max-Change: 0.02394 Iteration: 12, Log-Lik: -4472.467, Max-Change: 0.01826 Iteration: 13, Log-Lik: -4472.364, Max-Change: 0.02813 Iteration: 14, Log-Lik: -4472.305, Max-Change: 0.01578 Iteration: 15, Log-Lik: -4472.273, Max-Change: 0.01187 Iteration: 16, Log-Lik: -4472.230, Max-Change: 0.01645 Iteration: 17, Log-Lik: -4472.206, Max-Change: 0.00989 Iteration: 18, Log-Lik: -4472.192, Max-Change: 0.00770 Iteration: 19, Log-Lik: -4472.170, Max-Change: 0.01314 Iteration: 20, Log-Lik: -4472.156, Max-Change: 0.00704 Iteration: 21, Log-Lik: -4472.149, Max-Change: 0.00517 Iteration: 22, Log-Lik: -4472.141, Max-Change: 0.00631 Iteration: 23, Log-Lik: -4472.137, Max-Change: 0.00411 Iteration: 24, Log-Lik: -4472.134, Max-Change: 0.00333 Iteration: 25, Log-Lik: -4472.130, Max-Change: 0.00739 Iteration: 26, Log-Lik: -4472.125, Max-Change: 0.00345 Iteration: 27, Log-Lik: -4472.124, Max-Change: 0.00232 Iteration: 28, Log-Lik: -4472.123, Max-Change: 0.00210 Iteration: 29, Log-Lik: -4472.122, Max-Change: 0.00161 Iteration: 30, Log-Lik: -4472.122, Max-Change: 0.00138 Iteration: 31, Log-Lik: -4472.121, Max-Change: 0.00341 Iteration: 32, Log-Lik: -4472.120, Max-Change: 0.00154 Iteration: 33, Log-Lik: -4472.119, Max-Change: 0.00101 Iteration: 34, Log-Lik: -4472.119, Max-Change: 0.00087 Iteration: 35, Log-Lik: -4472.119, Max-Change: 0.00068 Iteration: 36, Log-Lik: -4472.119, Max-Change: 0.00059 Iteration: 37, Log-Lik: -4472.119, Max-Change: 0.00145 Iteration: 38, Log-Lik: -4472.119, Max-Change: 0.00065 Iteration: 39, Log-Lik: -4472.119, Max-Change: 0.00043 Iteration: 40, Log-Lik: -4472.119, Max-Change: 0.00038 Iteration: 41, Log-Lik: -4472.119, Max-Change: 0.00029 Iteration: 42, Log-Lik: -4472.119, Max-Change: 0.00025 Iteration: 43, Log-Lik: -4472.119, Max-Change: 0.00060 Iteration: 44, Log-Lik: -4472.119, Max-Change: 0.00028 Iteration: 45, Log-Lik: -4472.119, Max-Change: 0.00018 Iteration: 46, Log-Lik: -4472.119, Max-Change: 0.00017 Iteration: 47, Log-Lik: -4472.119, Max-Change: 0.00013 Iteration: 48, Log-Lik: -4472.119, Max-Change: 0.00011 Iteration: 49, Log-Lik: -4472.119, Max-Change: 0.00025 Iteration: 50, Log-Lik: -4472.119, Max-Change: 0.00011 Iteration: 51, Log-Lik: -4472.119, Max-Change: 0.00008 ## ## Calculating information matrix... Stiamiamo ora il DIF nella capacità discriminativa del solo item 6, utilizzando lo schema 'add'. #DIF in a al secondo step di purificazione DIF(mod.dif.2,which.par = &#39;a1&#39;, simplify = TRUE, scheme = &#39;add&#39;, items2test = item.candidati) ## converged AIC SABIC HQ BIC X2 df p ## ITEM_POLY_6 TRUE -4.934 -3.438 -3.138 -0.262 6.934 1 0.008 Il DIF nella capacità discrimiativa dellitem 6 è stato confermato anche al secondo step della procedura di purificazione (\\(X^2\\)(1)=6.93 , p &lt; .01), ad indicare che litem riusultava essere discriminare meglio le differenze di tratto nei maschi (a=1.65) rispetto alle femmine (a=1.19). Questo può essere anche analizzato graficamente tramite la funzione itemplot(). itemplot(mod.dif.2, item=6, type=&#39;trace&#39;, theta_lim = c(-3, 3)) Effect size del DIF Verifichiamo ora leffect size del DIF nel parametro dellitem 6, tramite la procdura descritta da Meade (2010). Effect size a livello di item In primo luogo valutiamo leffect size a livello di item, tramite gli indici e lispezione grafica. #Effect size al livello degli item #Indici empirical_ES(mod.dif.2) ## SIDS UIDS SIDN UIDN ESSD theta.of.max.D max.D mean.ES.foc ## item.1 0.000 0.000 0.0 0.000 0.000 -1.227 0.00 0.746 ## item.2 0.000 0.000 0.0 0.000 0.000 -1.227 0.00 0.674 ## item.3 0.000 0.000 0.0 0.000 0.000 -1.227 0.00 0.639 ## item.4 0.000 0.000 0.0 0.000 0.000 -1.227 0.00 0.691 ## item.5 0.000 0.000 0.0 0.000 0.000 -1.227 0.00 0.392 ## item.6 -0.109 0.173 -0.1 0.155 -0.219 2.964 -1.11 0.463 ## mean.ES.ref ## item.1 0.746 ## item.2 0.674 ## item.3 0.639 ## item.4 0.691 ## item.5 0.392 ## item.6 0.572 #Grafici empirical_ES(mod.dif.2, plot = TRUE) Effect size a livello di test Proseguiamo verificando limpatto del DIF sullintero test. #Effect Size a livello del test #Indici empirical_ES(mod.dif.2, DIF = FALSE) ## Effect Size Value ## 1 STDS -0.10917912 ## 2 UTDS 0.17281302 ## 3 UETSDS 0.17281302 ## 4 ETSSD -0.03021414 ## 5 Starks.DTFR -0.10014410 ## 6 UDTFR 0.15479671 ## 7 UETSDN 0.15479671 ## 8 theta.of.max.test.D 2.96352763 ## 9 Test.Dmax -1.11033082 #Grafici empirical_ES(mod.dif.2, DIF = FALSE, plot = TRUE) "],["scoring-di-strumenti-unidimensionali-politomici.html", "Scoring di strumenti unidimensionali politomici", " Scoring di strumenti unidimensionali politomici Per concludere, vediamo di seguito come è possibile effettuare lo scoring di un test politomico. Per farlo, utilizzeremo sempre Expected a Posteriori Score (EAP; Bock &amp; Mislevy, 1982). Dopo aver stimato il modello tramite la funzione mirt(), procediamo a calcolare lEAP tramite la funzione fscores(). Impostiamoa full.scores.SE=TRUE per ottenere anche la stima dellerrore associato alla misura. #Calcolo gli EAP scores eap&lt;-fscores(MOD.graded,method = &#39;EAP&#39;,full.scores.SE = TRUE) colnames(eap)[1]&lt;- &#39;EAP&#39; colnames(eap)[2]&lt;- &#39;SD_EAP&#39; Poiché viene stimato un punteggio per ogni rispondente, possiamo unire le nuove colonne al nostro database usando la funzione cbind(). #Unisco il punteggio EAP e la stima della precisione SD_EAP al database TEST.POLY.EAP&lt;-cbind(TEST.POLY,eap) TEST.POLY.EAP ## SESSO ITEM_POLY_1 ITEM_POLY_2 ITEM_POLY_3 ITEM_POLY_4 ITEM_POLY_5 ## 1 1 1 1 1 1 1 ## 2 1 1 1 1 1 1 ## 3 1 1 1 1 1 1 ## 4 1 1 1 1 1 1 ## 5 1 1 1 1 1 1 ## 6 1 1 1 1 1 1 ## 7 1 1 1 1 1 1 ## 8 1 1 1 1 1 1 ## 9 1 1 1 1 1 1 ## 10 1 1 1 1 1 1 ## 11 1 1 1 1 1 1 ## 12 1 1 1 1 1 1 ## 13 1 1 1 1 1 1 ## 14 1 1 1 1 1 1 ## 15 1 1 1 1 1 1 ## 16 1 1 1 1 1 1 ## 17 1 1 1 1 1 1 ## 18 1 1 1 1 1 1 ## 19 1 1 1 1 1 1 ## 20 1 1 1 1 1 1 ## 21 1 1 1 1 1 1 ## 22 1 1 1 1 1 1 ## 23 1 1 1 1 1 1 ## 24 1 1 1 1 1 1 ## 25 1 1 1 1 1 1 ## 26 1 1 1 1 1 1 ## 27 1 1 1 1 1 1 ## 28 1 1 1 1 1 1 ## 29 1 1 1 1 1 1 ## 30 1 1 1 1 1 1 ## 31 1 1 1 1 1 1 ## 32 1 1 1 1 1 1 ## 33 1 1 1 1 1 1 ## 34 1 1 1 1 1 1 ## 35 1 1 1 1 1 1 ## 36 1 1 1 1 1 1 ## 37 1 1 1 1 1 1 ## 38 1 1 1 1 1 1 ## 39 1 1 1 1 1 1 ## 40 1 1 1 1 1 1 ## 41 1 1 1 1 1 1 ## 42 1 1 1 1 1 1 ## 43 1 1 1 1 1 1 ## 44 1 1 1 1 1 1 ## 45 1 1 1 1 1 1 ## 46 1 1 1 1 1 1 ## 47 1 1 1 1 1 1 ## 48 1 1 1 1 1 1 ## 49 1 1 1 1 1 1 ## 50 1 1 1 1 1 1 ## 51 1 1 1 1 1 1 ## 52 1 1 1 1 1 1 ## 53 1 1 1 1 1 1 ## 54 1 1 1 1 1 1 ## 55 1 1 1 1 1 1 ## 56 1 1 1 1 1 1 ## 57 1 1 1 1 1 1 ## 58 1 1 1 1 1 1 ## 59 1 1 1 1 1 1 ## 60 1 1 1 1 1 1 ## 61 1 1 1 1 1 1 ## 62 1 1 1 1 1 1 ## 63 1 1 1 1 1 1 ## 64 1 1 1 1 1 1 ## 65 1 1 1 1 1 1 ## 66 1 1 1 1 1 1 ## 67 1 1 1 1 1 1 ## 68 1 1 1 1 1 1 ## 69 1 1 1 1 1 1 ## 70 1 1 1 1 1 1 ## 71 1 1 1 1 1 1 ## 72 1 1 1 1 1 1 ## 73 1 1 1 1 1 1 ## 74 1 1 1 1 1 1 ## 75 1 1 1 1 1 1 ## 76 1 1 1 1 1 1 ## 77 1 1 1 1 1 1 ## 78 1 1 1 1 1 1 ## 79 1 1 1 1 1 1 ## 80 1 1 1 1 1 1 ## 81 1 1 1 1 1 1 ## 82 1 1 1 1 1 1 ## 83 1 1 1 1 1 1 ## 84 1 1 1 1 1 1 ## 85 1 1 1 1 1 1 ## 86 1 1 1 1 1 1 ## 87 1 1 1 1 1 1 ## 88 1 1 1 1 1 1 ## 89 1 1 1 1 1 1 ## 90 1 1 1 1 1 1 ## 91 1 1 1 1 1 1 ## 92 1 1 1 1 1 1 ## 93 1 1 1 1 1 1 ## 94 1 1 1 1 1 1 ## 95 1 1 1 1 1 1 ## 96 1 1 1 1 1 1 ## 97 1 1 1 1 1 1 ## 98 1 1 1 1 1 1 ## 99 1 1 1 1 1 1 ## 100 1 1 1 1 1 1 ## 101 1 1 1 1 1 1 ## 102 1 1 1 1 1 1 ## 103 1 1 1 1 1 1 ## 104 1 1 1 1 1 1 ## 105 1 1 1 1 1 1 ## 106 1 2 1 1 1 1 ## 107 1 2 1 1 1 1 ## 108 1 2 1 1 1 1 ## 109 1 2 1 1 1 1 ## 110 1 2 1 1 1 1 ## 111 1 2 1 1 1 1 ## ITEM_POLY_6 EAP SD_EAP ## 1 1 -1.0645220 0.6589128 ## 2 1 -1.0645220 0.6589128 ## 3 1 -1.0645220 0.6589128 ## 4 1 -1.0645220 0.6589128 ## 5 1 -1.0645220 0.6589128 ## 6 1 -1.0645220 0.6589128 ## 7 1 -1.0645220 0.6589128 ## 8 1 -1.0645220 0.6589128 ## 9 1 -1.0645220 0.6589128 ## 10 1 -1.0645220 0.6589128 ## 11 1 -1.0645220 0.6589128 ## 12 1 -1.0645220 0.6589128 ## 13 1 -1.0645220 0.6589128 ## 14 1 -1.0645220 0.6589128 ## 15 1 -1.0645220 0.6589128 ## 16 1 -1.0645220 0.6589128 ## 17 1 -1.0645220 0.6589128 ## 18 1 -1.0645220 0.6589128 ## 19 1 -1.0645220 0.6589128 ## 20 1 -1.0645220 0.6589128 ## 21 1 -1.0645220 0.6589128 ## 22 1 -1.0645220 0.6589128 ## 23 1 -1.0645220 0.6589128 ## 24 1 -1.0645220 0.6589128 ## 25 1 -1.0645220 0.6589128 ## 26 1 -1.0645220 0.6589128 ## 27 1 -1.0645220 0.6589128 ## 28 1 -1.0645220 0.6589128 ## 29 1 -1.0645220 0.6589128 ## 30 1 -1.0645220 0.6589128 ## 31 1 -1.0645220 0.6589128 ## 32 1 -1.0645220 0.6589128 ## 33 1 -1.0645220 0.6589128 ## 34 1 -1.0645220 0.6589128 ## 35 1 -1.0645220 0.6589128 ## 36 1 -1.0645220 0.6589128 ## 37 1 -1.0645220 0.6589128 ## 38 1 -1.0645220 0.6589128 ## 39 1 -1.0645220 0.6589128 ## 40 1 -1.0645220 0.6589128 ## 41 1 -1.0645220 0.6589128 ## 42 1 -1.0645220 0.6589128 ## 43 1 -1.0645220 0.6589128 ## 44 1 -1.0645220 0.6589128 ## 45 1 -1.0645220 0.6589128 ## 46 1 -1.0645220 0.6589128 ## 47 1 -1.0645220 0.6589128 ## 48 1 -1.0645220 0.6589128 ## 49 1 -1.0645220 0.6589128 ## 50 1 -1.0645220 0.6589128 ## 51 1 -1.0645220 0.6589128 ## 52 1 -1.0645220 0.6589128 ## 53 1 -1.0645220 0.6589128 ## 54 1 -1.0645220 0.6589128 ## 55 1 -1.0645220 0.6589128 ## 56 1 -1.0645220 0.6589128 ## 57 1 -1.0645220 0.6589128 ## 58 1 -1.0645220 0.6589128 ## 59 1 -1.0645220 0.6589128 ## 60 1 -1.0645220 0.6589128 ## 61 1 -1.0645220 0.6589128 ## 62 1 -1.0645220 0.6589128 ## 63 1 -1.0645220 0.6589128 ## 64 1 -1.0645220 0.6589128 ## 65 1 -1.0645220 0.6589128 ## 66 1 -1.0645220 0.6589128 ## 67 1 -1.0645220 0.6589128 ## 68 1 -1.0645220 0.6589128 ## 69 1 -1.0645220 0.6589128 ## 70 1 -1.0645220 0.6589128 ## 71 1 -1.0645220 0.6589128 ## 72 1 -1.0645220 0.6589128 ## 73 1 -1.0645220 0.6589128 ## 74 1 -1.0645220 0.6589128 ## 75 1 -1.0645220 0.6589128 ## 76 1 -1.0645220 0.6589128 ## 77 1 -1.0645220 0.6589128 ## 78 1 -1.0645220 0.6589128 ## 79 1 -1.0645220 0.6589128 ## 80 1 -1.0645220 0.6589128 ## 81 1 -1.0645220 0.6589128 ## 82 1 -1.0645220 0.6589128 ## 83 1 -1.0645220 0.6589128 ## 84 1 -1.0645220 0.6589128 ## 85 1 -1.0645220 0.6589128 ## 86 1 -1.0645220 0.6589128 ## 87 1 -1.0645220 0.6589128 ## 88 1 -1.0645220 0.6589128 ## 89 1 -1.0645220 0.6589128 ## 90 1 -1.0645220 0.6589128 ## 91 1 -1.0645220 0.6589128 ## 92 1 -1.0645220 0.6589128 ## 93 1 -1.0645220 0.6589128 ## 94 1 -1.0645220 0.6589128 ## 95 1 -1.0645220 0.6589128 ## 96 1 -1.0645220 0.6589128 ## 97 1 -1.0645220 0.6589128 ## 98 1 -1.0645220 0.6589128 ## 99 1 -1.0645220 0.6589128 ## 100 1 -1.0645220 0.6589128 ## 101 1 -1.0645220 0.6589128 ## 102 1 -1.0645220 0.6589128 ## 103 1 -1.0645220 0.6589128 ## 104 1 -1.0645220 0.6589128 ## 105 1 -1.0645220 0.6589128 ## 106 1 -0.5011203 0.5212141 ## 107 1 -0.5011203 0.5212141 ## 108 1 -0.5011203 0.5212141 ## 109 1 -0.5011203 0.5212141 ## 110 1 -0.5011203 0.5212141 ## 111 1 -0.5011203 0.5212141 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 679 rows ] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
